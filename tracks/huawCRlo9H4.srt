1
00:00:02,280 --> 00:00:06,910
>>Lars Bak: Good morning, and welcome to the
second day of Google I/O. I hope you all enjoyed

2
00:00:06,910 --> 00:00:10,250
the party yesterday with Billy Idol.
[ Laughter ]

3
00:00:10,250 --> 00:00:14,039
>>Lars Bak: Yeah. From my youth.
[ Laughter ]

4
00:00:14,039 --> 00:00:21,039
>>Lars Bak: So we want to talk about web programming
languages and virtual machines and we're trying

5
00:00:22,540 --> 00:00:29,290
to argue why it's important to always make
it faster so that you guys can make better

6
00:00:29,290 --> 00:00:33,090
applications.
I'm Lars Bak. I'm the blue guy. And this is

7
00:00:33,090 --> 00:00:35,260
Kasper Lund &mdash;
>>Kasper Lund: I'm the red guy.

8
00:00:35,260 --> 00:00:36,089
>>Lars Bak: &mdash; the red guy.
[ Laughter ]

9
00:00:36,089 --> 00:00:43,089
>>Lars Bak: And we are from Google, from the
Danish engineering office, so if we look tired,

10
00:00:44,710 --> 00:00:51,030
it's jet lag.
All right. So just to know &mdash; so you know

11
00:00:51,030 --> 00:00:58,030
who we are, we've been working on virtual
machines for too long. I started in '86, and

12
00:00:58,370 --> 00:01:02,510
in '86 working on virtual machines for their
programming languages was sort of a little

13
00:01:02,510 --> 00:01:07,659
bit niche, and it was only research communities
that had an interest in it.

14
00:01:07,659 --> 00:01:12,680
But given today we have several hundred people
here, I'm pleased that there's more interest

15
00:01:12,680 --> 00:01:16,860
for it.
So I started working with Kasper 13 years

16
00:01:16,860 --> 00:01:23,860
ago and we've been doing Java virtual machines,
Smalltalk virtual machines, JavaScript virtual

17
00:01:24,670 --> 00:01:29,219
machines, and now Dart, so we sort of have
a little bit of experience in doing compilers

18
00:01:29,219 --> 00:01:35,829
and garbage collectors, so hopefully we can
tell you about some of our findings over the

19
00:01:35,829 --> 00:01:42,759
last many years.
So why are we here? We're here because we

20
00:01:42,759 --> 00:01:48,409
truly believe that speed in web browsers fuel
innovations for application developers, right?

21
00:01:48,409 --> 00:01:53,700
The more speed we can give you, the more interesting
applications you can do. And we strongly believe

22
00:01:53,700 --> 00:01:58,799
in the fly-by web, right? Developers do one
application &mdash; it runs on mobile phones and

23
00:01:58,799 --> 00:02:05,320
desktop systems &mdash; and this is just fantastic.
And the source that makes it work is the virtual

24
00:02:05,320 --> 00:02:09,429
machine inside the browser.
And if we can make it faster, you can take

25
00:02:09,429 --> 00:02:14,140
advantage of it.
The question is, we have seen a lot of speedup

26
00:02:14,140 --> 00:02:20,900
in browsers over the last, I guess, five years.
Is it fast enough or do we want more speed?

27
00:02:20,900 --> 00:02:26,200
So we are of the opinion that we need to do
even better, and that is one of the reasons

28
00:02:26,200 --> 00:02:31,200
why we have started on this new venture to
do a Dart platform.

29
00:02:31,200 --> 00:02:38,200
>>Kasper Lund: So before we dive into the
technical details of virtual machines and

30
00:02:38,560 --> 00:02:44,780
programming for the web, I just wanted to
take you back to 2006 when we started developing

31
00:02:44,780 --> 00:02:51,650
V8. At that point, Web pages had evolved from
being fairly static to being a little bit

32
00:02:51,650 --> 00:02:56,849
more rich, and we were seeing sort of the
first Web applications appear. At the point

33
00:02:56,849 --> 00:03:02,290
in time, you were probably running Firefox
2.0, Internet Explorer 7.0, or some other

34
00:03:02,290 --> 00:03:08,000
browsers there, but it was very clear that
these browsers were not really designed for

35
00:03:08,000 --> 00:03:12,200
long-running, heavy Web applications. They
were designed for the web of two thousand-

36
00:03:12,200 --> 00:03:16,530
&mdash; well, probably 2000, yeah.
And so it was an interesting at that point

37
00:03:16,530 --> 00:03:21,560
in time, 2006, it was just before we were
seeing these applications really come to life

38
00:03:21,560 --> 00:03:26,580
on the web. And even if you &mdash; if you look
at the Web sites I've depicted up here, you

39
00:03:26,580 --> 00:03:30,959
can tell the difference, if you can actually
see it from the back of the room, that in

40
00:03:30,959 --> 00:03:34,670
2008, already then we were seeing pages like
BBC becoming a little bit more interactive

41
00:03:34,670 --> 00:03:40,060
and more rich.
So in 2006 when we set out to implement a

42
00:03:40,060 --> 00:03:44,260
new virtual machine for JavaScript for the
web, people believed that browsers were essentially

43
00:03:44,260 --> 00:03:48,939
fast enough. Web applications like Gmail and
Google Maps ran fine and people were very

44
00:03:48,939 --> 00:03:54,150
impressed with them. People also believed
that JavaScript was just inherently too slow

45
00:03:54,150 --> 00:04:00,230
for writing heavy client-side computations.
And even so, people didn't really expect the

46
00:04:00,230 --> 00:04:04,930
JavaScript to improve that much so they didn't
think that the execution of JavaScript was

47
00:04:04,930 --> 00:04:09,969
holding things back. They were okay with having
more code running on the server side and having

48
00:04:09,969 --> 00:04:15,269
fairly limited amounts of logic on the client
side.

49
00:04:15,269 --> 00:04:19,690
Another key thing for us when we started was
that performance at that point was evaluated

50
00:04:19,690 --> 00:04:24,630
using very simple micro-benchmarks, where
all the emphasis was put on simple loops with

51
00:04:24,630 --> 00:04:30,940
very simple arithmetic and nobody paid any
attention to the overhead for calling methods

52
00:04:30,940 --> 00:04:35,720
or how large applications would perform when
it comes to memory management.

53
00:04:35,720 --> 00:04:40,060
So people were really spending all their time
looking at small, simple loops and trying

54
00:04:40,060 --> 00:04:44,520
to make them run a little bit faster.
So here's an example of a benchmark that I

55
00:04:44,520 --> 00:04:47,210
think represents that line of thought pretty
well.

56
00:04:47,210 --> 00:04:51,800
This is a benchmark, a JavaScript benchmark,
from the SunSpider benchmark collection. It's

57
00:04:51,800 --> 00:04:57,130
known as "bit-wise and" and that's all it
does. It computes the bit-wise and for a series

58
00:04:57,130 --> 00:05:01,550
of values here, starting out with a fairly
large number and then it runs through a loop

59
00:05:01,550 --> 00:05:08,080
and you'll probably notice that even on the
iteration, I is zero so when you "and" that

60
00:05:08,080 --> 00:05:14,289
with anything, you'll get zero out. So this
is just a fancy way of computing zero.

61
00:05:14,289 --> 00:05:17,740
Not exactly something you want to spend a
lot of time on optimizing for, I guess, and

62
00:05:17,740 --> 00:05:21,539
certainly not something that would, if you
actually did optimize this, it would turn

63
00:05:21,539 --> 00:05:26,600
your application any faster.
So SunSpider is a benchmark that sort of represents

64
00:05:26,600 --> 00:05:32,150
some of the things and some of the problems
from sort of the earlier web, and they &mdash; it

65
00:05:32,150 --> 00:05:36,090
is being updated every now and then but not
with any significant differences. This is

66
00:05:36,090 --> 00:05:41,600
from SunSpider 1.0 released a couple of weeks
ago. It's very nice to see that they've added

67
00:05:41,600 --> 00:05:46,280
testing that actually does compute zero but
it's still a really bad benchmark. Making

68
00:05:46,280 --> 00:05:50,560
this faster and tuning V8 for these kind of
things would not make your applications run

69
00:05:50,560 --> 00:05:55,710
any faster, so...
So when we started designing V8, we had to

70
00:05:55,710 --> 00:05:58,819
make a choice. Like what do we want to optimize
for?

71
00:05:58,819 --> 00:06:02,960
And there are basically two approaches.
You can optimize for the current apps and

72
00:06:02,960 --> 00:06:07,710
the current benchmarks, and that's a nice
and simple incremental approach, and there's

73
00:06:07,710 --> 00:06:13,539
a good chance you can make things 10%, maybe
20% faster that way. And we chose to optimize

74
00:06:13,539 --> 00:06:18,020
for the apps of the future at that point so
we decided that we wanted to support much

75
00:06:18,020 --> 00:06:21,910
heavier side client-side computations and
we wanted to turn the browser into a scalable

76
00:06:21,910 --> 00:06:27,830
application platform, sort of thus enabling
a new class of Webapps that could be written.

77
00:06:27,830 --> 00:06:33,169
So optimizing a brand-new virtual machine
for some applications that you cannot write

78
00:06:33,169 --> 00:06:39,770
&mdash; or you couldn't write in 2006 &mdash; required
us to come up with some benchmarks and some

79
00:06:39,770 --> 00:06:42,949
metrics that would allow us to make progress
on that problem.

80
00:06:42,949 --> 00:06:47,280
Which is where the V8 benchmark suite entered
the game.

81
00:06:47,280 --> 00:06:51,590
So the V8 benchmark suite is a collection
of benchmarks that are structured and mostly

82
00:06:51,590 --> 00:06:58,590
object-oriented, and they're designed to push
the limits of browsers in 2006 but also today,

83
00:06:58,710 --> 00:07:03,660
and it's benchmarks that are mostly proven
valuable in the context of lots of other languages.

84
00:07:03,660 --> 00:07:07,699
So it's benchmarks that we know that if we
optimize for those, it will actually make

85
00:07:07,699 --> 00:07:11,599
it possible for you guys to write much larger
and much more interesting applications.

86
00:07:11,599 --> 00:07:17,319
It measures the performance of dynamic message
calls and property access and it also measures

87
00:07:17,319 --> 00:07:21,069
the performance of the memory management system,
and closure creation and location, to a much

88
00:07:21,069 --> 00:07:23,970
higher degree than any of the existing benchmarks
in 2006.

89
00:07:23,970 --> 00:07:29,539
>>Lars Bak: But Kasper, can I get the mic?
Thank you. Let's try to run it so we can see

90
00:07:29,539 --> 00:07:33,759
how it looks.
So here, let's search for the V8 benchmark

91
00:07:33,759 --> 00:07:39,580
suite and we can run Version 7 of it, and
it will start running and you'll see the results

92
00:07:39,580 --> 00:07:43,660
trickling in on the right-hand side and you
can see the collection of benchmarks we are

93
00:07:43,660 --> 00:07:47,599
running. It's eight different benchmarks.
They're not big, but they are certainly not

94
00:07:47,599 --> 00:07:53,580
micro-benchmarks.
And we should soon have the results.

95
00:07:53,580 --> 00:08:00,580
The interesting part is that the score you
see is computed as the geometric mean between

96
00:08:01,039 --> 00:08:08,039
individual scores but it's calibrated for
Firefox 2 on a high-end desktop machine in

97
00:08:09,669 --> 00:08:16,669
2008.
So we are pretty much running 160 times faster

98
00:08:17,280 --> 00:08:20,810
than one of the browsers in 2008, so this
is pretty amazing.

99
00:08:20,810 --> 00:08:25,889
>>Kasper Lund: Yeah. The score was 100 on
Firefox 2 on my beefy desktop machine in 2008.

100
00:08:25,889 --> 00:08:31,289
It's a little bit better now. Which is nice.
[ Laughter ]

101
00:08:31,289 --> 00:08:38,289
>>Kasper Lund: So I think it's fair to conclude
that the performance improvements for JavaScript

102
00:08:39,170 --> 00:08:43,630
over the last eight years have been pretty
impressive. JavaScript itself executes a hundred

103
00:08:43,630 --> 00:08:48,840
times faster than it did before, at least,
and we see people being able to write applications

104
00:08:48,840 --> 00:08:54,160
that use way bigger object heaps, and the
GC pauses are even lower than they were at

105
00:08:54,160 --> 00:08:58,020
that point.
Another key thing for us as compilers and

106
00:08:58,020 --> 00:09:02,170
VM engineers is that people pay attention
now to performance of their Webapps and it's

107
00:09:02,170 --> 00:09:07,570
very, very common to see benchmark numbers
reported in the press, so it's a &mdash; there's

108
00:09:07,570 --> 00:09:12,690
a nice friendly competition going on to improve
the web platform performance.

109
00:09:12,690 --> 00:09:16,160
Another thing that's very nice to see is that
it's possible to write really large Webapps

110
00:09:16,160 --> 00:09:22,680
these days. We see common pages like Amazon,
CNN, and ESPN have &mdash; they're serving fairly

111
00:09:22,680 --> 00:09:28,160
large amounts of JavaScript codes to their
customers all day, so it's not uncommon to

112
00:09:28,160 --> 00:09:34,770
see like a megabyte of JavaScript code, minified
JavaScript code, being sent to clients. And

113
00:09:34,770 --> 00:09:38,900
the browsers are generally capable of working
with that. So things have certainly changed

114
00:09:38,900 --> 00:09:44,750
since 2006.
One thing that is important for us is to pay

115
00:09:44,750 --> 00:09:49,500
attention to where the time is actually spent
in your browser, and what you have here is

116
00:09:49,500 --> 00:09:56,500
a couple of diagrams that show that we're
spending around 60% of the time in JavaScript

117
00:09:57,450 --> 00:10:01,570
execution when you're running things like
Gmail, Google Docs, Google Search, and things

118
00:10:01,570 --> 00:10:06,610
like that, and the rest is spent in the general
browser infrastructure.

119
00:10:06,610 --> 00:10:09,750
On other sites like Twitter and Facebook,
the percentage in JavaScript is a little bit

120
00:10:09,750 --> 00:10:15,590
lower than that. And these measurements are
all done by the Chrome team using Chrome,

121
00:10:15,590 --> 00:10:20,070
so we don't have the exact same numbers for
the other browsers. But it shows that no matter

122
00:10:20,070 --> 00:10:25,580
how fast we make the engines, the application
developers will adapt to that and add new

123
00:10:25,580 --> 00:10:30,530
functionality and essentially make their applications
better by using this thing.

124
00:10:30,530 --> 00:10:36,190
So imagine how it would feel like running
modern Gmail on a browser from 2006. I don't

125
00:10:36,190 --> 00:10:42,670
think you would like that at all.
So today, web developers are really pushing

126
00:10:42,670 --> 00:10:46,880
the limits of the platform and they really
want and demand predictable high performance.

127
00:10:46,880 --> 00:10:49,970
Higher and higher, actually.
They want consistent frame rates for their

128
00:10:49,970 --> 00:10:54,000
games. And they really want to support large-scale
application development.

129
00:10:54,000 --> 00:10:58,210
So people's expectations for this platform
have really changed. They really demand these

130
00:10:58,210 --> 00:11:02,870
things now, and all it took is 100X performance
improvement. It makes a really, really big

131
00:11:02,870 --> 00:11:06,120
change to the technology stack when you do
these things.

132
00:11:06,120 --> 00:11:12,690
So the question is, of course, are the web
developers getting predictable and high performance,

133
00:11:12,690 --> 00:11:16,120
and can they actually support really large-scale
application development on the current web

134
00:11:16,120 --> 00:11:18,790
stack?
So before we answer that question, I think

135
00:11:18,790 --> 00:11:22,610
we should dive into the &mdash; the current web
stack and take a look at how we can improve

136
00:11:22,610 --> 00:11:29,300
the parts.
>>Lars Bak: All right. Now we'll dive into

137
00:11:29,300 --> 00:11:32,930
what actually happens inside the virtual machine
and the browser.

138
00:11:32,930 --> 00:11:37,730
So I'll be talking about a few different techniques
we've been using to make V8 fast and I'll

139
00:11:37,730 --> 00:11:44,730
talk about the history behind these technologies.
Firstly, let's look at a browser. So a browser

140
00:11:45,460 --> 00:11:52,150
has several parts. But if we look at the performance-critical
part for a Webapp, it actually consists of

141
00:11:52,150 --> 00:11:56,060
two segments.
At the lower part, we have the JavaScript

142
00:11:56,060 --> 00:12:02,690
engine where you have all the code and the
objects and the WebObjects that point to the

143
00:12:02,690 --> 00:12:08,710
DOM. The DOM consists of the &mdash; the nodes
that you can see on the screen. And when you

144
00:12:08,710 --> 00:12:15,060
execute your Web application, you manipulate
the DOM by executing JavaScript.

145
00:12:15,060 --> 00:12:21,430
We all hope that when you develop a Web application,
you have low latency so it comes up fast and

146
00:12:21,430 --> 00:12:27,920
there's no pauses, it has high performance,
and it also has low memory usage so you don't

147
00:12:27,920 --> 00:12:32,230
end up swapping when you run your application.
And then, of course, more pauses if you do

148
00:12:32,230 --> 00:12:37,110
animation. But there are still big fears when
you run a Web application, right?

149
00:12:37,110 --> 00:12:43,140
If the object heap is too big, you can get
very large GC pauses, and you can have memory

150
00:12:43,140 --> 00:12:49,180
leaks. So having a Web application that runs
for weeks and suddenly it runs out of memory

151
00:12:49,180 --> 00:12:53,750
is not very pleasant for the user.
And sometimes you'll get erratic performance

152
00:12:53,750 --> 00:12:59,450
behavior for no good reasons.
And this is sort of some of the issues people

153
00:12:59,450 --> 00:13:06,450
are concerned about when writing for the web.
Here is my picture of how a virtual machine

154
00:13:08,210 --> 00:13:11,730
or a JavaScript engine looked like in the
year 2006.

155
00:13:11,730 --> 00:13:17,790
It had a simple parser that would take the
source code and convert into an abstract syntax

156
00:13:17,790 --> 00:13:22,260
tree or into byte codes and then it would
have a simplistic interpreter that would run

157
00:13:22,260 --> 00:13:29,120
over the AST, abstract syntax tree, or the
byte codes and execute the program.

158
00:13:29,120 --> 00:13:33,480
And then it would have a simple memory management
system to clean out unused memory.

159
00:13:33,480 --> 00:13:39,010
Now, in 2006 you would not create many objects
because you knew that if you created a lot

160
00:13:39,010 --> 00:13:44,000
of objects, your program would be slow, so
you actually didn't use many of the object-oriented

161
00:13:44,000 --> 00:13:49,040
qualities of the system.
So the conclusion is, it was very simple and

162
00:13:49,040 --> 00:13:53,890
that's nice that you can write this kind of
VM in a few thousand lines, but the downside

163
00:13:53,890 --> 00:13:59,810
was it was really slow.
Today, we have a sports car and I can guarantee

164
00:13:59,810 --> 00:14:06,060
you we have put in all kinds of fancy turbo
engines in it to make it fast, right? We still

165
00:14:06,060 --> 00:14:12,560
have a parser, but instead of an interpreter,
we have a multi-tier adaptive compilation

166
00:14:12,560 --> 00:14:18,600
system. It's basically a &mdash; it's a series
of compilers that learns from the behavior

167
00:14:18,600 --> 00:14:24,450
of the program and tries to optimize the execution
based on behavior.

168
00:14:24,450 --> 00:14:30,330
We have a de-optimization system that allows
the system to back out of optimization if

169
00:14:30,330 --> 00:14:36,220
the behavior of the program changes over time.
And then we have a system that handles large

170
00:14:36,220 --> 00:14:42,890
object heaps. And in the V8 case, we have
a generation-based garbage collector that

171
00:14:42,890 --> 00:14:47,720
allows us to have heaps up to a gigabyte,
at least, where you can still have reasonable

172
00:14:47,720 --> 00:14:54,720
pauses when running your program.
Native code is generated on the fly and is

173
00:14:54,870 --> 00:15:00,200
generated by the buckets, I guarantee you,
and what will happen when it's not used anymore,

174
00:15:00,200 --> 00:15:05,410
it will be removed by the garbage collector.
So even return addresses on the execution

175
00:15:05,410 --> 00:15:11,390
stack will function like pointers into the
code, and if they are not used anymore, the

176
00:15:11,390 --> 00:15:16,310
code will be eliminated.
And then of course there's all this tool sport

177
00:15:16,310 --> 00:15:19,529
with debugging and profiling.
Because when you do optimizations &mdash; right?

178
00:15:19,529 --> 00:15:25,180
&mdash; you sort of lose the understanding of what
the source code is doing, so you cannot single-step

179
00:15:25,180 --> 00:15:28,080
an optimized code. It will give no meaning
to you.

180
00:15:28,080 --> 00:15:33,630
So what we try to do is we try to de-optimize
the code. If we try to single-step, it will

181
00:15:33,630 --> 00:15:39,100
look like you do single-stepping in the normal
source code. And that's great for a programmer,

182
00:15:39,100 --> 00:15:43,570
because then you can debug on an odd-based
system or an intra-based system and get exactly

183
00:15:43,570 --> 00:15:50,020
the same behavior.
It's really complex, but the good thing is,

184
00:15:50,020 --> 00:15:55,200
it's fast.
Let's go beyond the hood and see what's going

185
00:15:55,200 --> 00:15:58,830
on inside the V8 engine when it comes to a
few things.

186
00:15:58,830 --> 00:16:04,820
I'll briefly mention how we make the code
really fast, and this is this multi-tier adaptive

187
00:16:04,820 --> 00:16:09,220
compilation system.
I'll talk about how we handle large object

188
00:16:09,220 --> 00:16:14,860
heaps by doing this generation-based garbage
collection with a twist.

189
00:16:14,860 --> 00:16:21,860
And then I'll talk about how we bind JavaScript
objects to the DOM nodes.

190
00:16:22,260 --> 00:16:28,940
And this is &mdash; this is tricky, so I'm calling
it the tangoing between the tracing GC and

191
00:16:28,940 --> 00:16:35,940
reference counting.
So listen up. This might be a little bit tricky

192
00:16:36,530 --> 00:16:41,870
here.
When you parse the code, the code is blue.

193
00:16:41,870 --> 00:16:47,370
You have a sea of JavaScript methods. Nothing
has been executed yet. When you start executing,

194
00:16:47,370 --> 00:16:52,640
the first simplistic compiler will take the
source code and convert into native code,

195
00:16:52,640 --> 00:16:55,570
right?
It doesn't know much about the behavior of

196
00:16:55,570 --> 00:17:01,670
the program, so what it's doing is putting
in inline cache stops that tracks the behavior

197
00:17:01,670 --> 00:17:06,160
of the program. So in essence, what it's doing
at one call site in the program, it tries

198
00:17:06,160 --> 00:17:11,660
to figure out exactly what kind of type of
objects comes by.

199
00:17:11,660 --> 00:17:16,690
At the same time, we have this monitoring
system in the system that detects when a method

200
00:17:16,690 --> 00:17:21,850
is used frequently. If it's used frequently,
we said, "Well, let's try to optimize it even

201
00:17:21,850 --> 00:17:27,430
further." And the optimizing native compiler,
what it will do, it will take the collected

202
00:17:27,430 --> 00:17:34,000
type information from the inline caches and
use that to do aggressive inlining.

203
00:17:34,000 --> 00:17:38,920
So it basically assumes that the behavior
of the program you had before you optimized

204
00:17:38,920 --> 00:17:45,380
will be the same in all future. It's not always
the case, but we're optimistic here.

205
00:17:45,380 --> 00:17:50,660
So we do these aggressive inlining decisions,
but we put in the optimization hook so that

206
00:17:50,660 --> 00:17:56,350
if our assumptions are wrong in the optimized
code, we can go back again to the naive, simple

207
00:17:56,350 --> 00:17:59,630
code.
In most cases, we don't have to do that and

208
00:17:59,630 --> 00:18:05,360
you'll get the predictable performance, which
is great.

209
00:18:05,360 --> 00:18:12,360
It gets even harder &mdash; right? &mdash; because as
you all know, there's no types in JavaScript,

210
00:18:12,360 --> 00:18:17,720
and that means we have to do funky stuff.
One funky thing we are doing is that if you

211
00:18:17,720 --> 00:18:24,480
use an array and you put doubles in it, at
some point at runtime we decide to optimize

212
00:18:24,480 --> 00:18:30,570
it by converting the representation of an
object from an array that can have any kind

213
00:18:30,570 --> 00:18:36,050
of objects to a representation that can only
have double values. Right?

214
00:18:36,050 --> 00:18:40,350
So we assume that moving forward, we will
only operate on double values in this array.

215
00:18:40,350 --> 00:18:44,380
That will certainly speed up programs that
continue to have that behavior, but you still

216
00:18:44,380 --> 00:18:49,050
need the hooks if something from the side
would put in an integer. Or not an integer.

217
00:18:49,050 --> 00:18:55,980
Let's say a &mdash; a string in that array.
Then we have to back out of that optimization

218
00:18:55,980 --> 00:19:00,620
and go back to the standard representation
of an object array. Very complicated.

219
00:19:00,620 --> 00:19:07,620
But anyways, you have a system that's always
changing when you run it.

220
00:19:09,310 --> 00:19:14,910
Did we invent this multi-tier adaptive compilation?
No, we are not that smart. There is actually

221
00:19:14,910 --> 00:19:21,910
a long history of implementing dynamic languages,
started with interpretation in the '50s with

222
00:19:24,830 --> 00:19:29,930
Lisp. In the '70s, we have dynamic compilation
being added to Smalltalk. And they even had

223
00:19:29,930 --> 00:19:34,990
inline caching. It was not at the call side,
but they put it at the callee. So instead

224
00:19:34,990 --> 00:19:38,750
of having it &mdash; the method calling it, it
was actually at the prologue of the method

225
00:19:38,750 --> 00:19:43,570
you called.
And then the adaptive compilation was invented

226
00:19:43,570 --> 00:19:48,890
in the '90s in the sales project where you
have mixed mode execution, runtime-type feedback

227
00:19:48,890 --> 00:19:53,840
and all this kind of stuff.
And then they also came up with deoptimization.

228
00:19:53,840 --> 00:19:58,160
So let me try to explain what deoptimization
is. It is actually very simple.

229
00:19:58,160 --> 00:20:03,540
When you have the optimized code and you have
activations on the stack that's executing

230
00:20:03,540 --> 00:20:08,820
and you figure out that something is wrong,
you need to revert. What you do is you take

231
00:20:08,820 --> 00:20:15,820
that optimized activation and convert it into
a series of unoptimized activity on the stack,

232
00:20:17,810 --> 00:20:24,660
flush the optimized code, and start using
the simple code again.

233
00:20:24,660 --> 00:20:29,650
This first appeared commercially in the HotSpot
JVM. I assume you all know about what that

234
00:20:29,650 --> 00:20:34,800
is.
The other thing we did in V8 to basically

235
00:20:34,800 --> 00:20:41,480
use all this technology was introducing behind-the-scenes
classes. You know that JavaScript is prototype-based,

236
00:20:41,480 --> 00:20:46,600
but we faked them behind the scenes in event
classes. Then you can apply all this technology

237
00:20:46,600 --> 00:20:53,600
on the slide, and that made it fast.
The garbage collector in V8 is here. It might

238
00:20:57,870 --> 00:21:03,590
look complicated. We basically have two generations.
And the way it works is, as you are allocating

239
00:21:03,590 --> 00:21:10,360
optics in your program, we will fill up the
allocation space. It is called "from" here.

240
00:21:10,360 --> 00:21:16,160
When it is full, we will start a garbage collection
process. And we have a tracing garbage collector.

241
00:21:16,160 --> 00:21:20,650
That means that we have well-defined routes,
and we start following these routes through

242
00:21:20,650 --> 00:21:27,650
the optics, through its references until we
have computed the complete live optigraph.

243
00:21:28,240 --> 00:21:33,730
And memory that's not occupied by the live
optigraph is garbage, and it can be reclaimed

244
00:21:33,730 --> 00:21:38,170
and used for further objects.
Let's see what happens when you do a use-space

245
00:21:38,170 --> 00:21:45,170
collection in V8. We migrate the optics to
the "to" space. And you can see it is smaller,

246
00:21:47,440 --> 00:21:51,820
and that is because most optics die young.
And this is great.

247
00:21:51,820 --> 00:21:58,820
Then we can start allocating and filling up
the "to" space and repeat the same story.

248
00:21:59,040 --> 00:22:06,040
The garbage collector in V8 is a precise garbage
collector. It stops the world and processes

249
00:22:06,530 --> 00:22:13,240
the garbage and then continues on.
You can see you have red pointers in the graph.

250
00:22:13,240 --> 00:22:18,830
It denotes that the system has a stop buffer
that tracks pointers from old generation to

251
00:22:18,830 --> 00:22:24,210
the new generation. And you need that if you
want to do fast use-space garbage collection.

252
00:22:24,210 --> 00:22:29,560
You don't have to scan the whole heap in order
to do a small garbage collection.

253
00:22:29,560 --> 00:22:36,560
The old space in V8 has been segmented into
normal optics. That's the optics that's promoted

254
00:22:38,010 --> 00:22:44,100
from use-space when they have survived for
a while, and then native code where you have

255
00:22:44,100 --> 00:22:50,390
native instructions, and then a segment where
you have atomic data. Atomic data is data

256
00:22:50,390 --> 00:22:56,600
that does not have pointers out again. So
it could be typed arrays or double optics,

257
00:22:56,600 --> 00:23:00,320
something like that. That is easier to handle
in a separate space because they don't have

258
00:23:00,320 --> 00:23:06,900
pointers out.
Anyways, we didn't invent that either. Sorry.

259
00:23:06,900 --> 00:23:13,900
There's a long history of automatic memory
management done in Lisp in the '50s. Incremental

260
00:23:14,180 --> 00:23:19,770
garbage collection done in the '70s in Lisp
as well. And then you have generational-based

261
00:23:19,770 --> 00:23:26,240
garbage collection that got invented by the
one guy in the '80s and generationally scavenged

262
00:23:26,240 --> 00:23:31,320
any use of Smalltalk.
So all these techniques for doing garbage

263
00:23:31,320 --> 00:23:35,970
collection is fairly simple in my mind because
you have all the pointers to the optics and

264
00:23:35,970 --> 00:23:40,530
you can just process them.
The hard part is actually dancing with the

265
00:23:40,530 --> 00:23:47,530
DOM. And I will try to tell you how that works.
So nodes in DOM is going by what we call reference

266
00:23:49,880 --> 00:23:55,500
counting. Reference counting is a simplistic
garbage collection technology that keeps a

267
00:23:55,500 --> 00:24:02,500
pointer in each optic that tells how many
pointers point to it. When that pointer goes

268
00:24:02,610 --> 00:24:08,510
to zero, you can de-allocate the optic.
The problem is you don't know who points to

269
00:24:08,510 --> 00:24:14,380
it. You just know how many. That means that
if you want to move the optic memory, you

270
00:24:14,380 --> 00:24:17,900
cannot do that because you cannot find how
to point to it.

271
00:24:17,900 --> 00:24:24,670
And another deficiency of that mechanism is
also if you have a cycle, which can happen,

272
00:24:24,670 --> 00:24:31,670
then it's a memory leak because you will never
get down to zero in the reference count.

273
00:24:32,230 --> 00:24:37,330
And the problem is JavaScript V8 has optics
that are traced and we have to get all this

274
00:24:37,330 --> 00:24:44,330
to work.
So, here we go. Bear with me. This is complicated.

275
00:24:44,630 --> 00:24:50,550
On the top you see the DOM. You have two nodes.
The first node has a reference count of 1.

276
00:24:50,550 --> 00:24:57,550
The second one has a count of 2. And you have
wrapper optics that point to these DOM nodes

277
00:24:57,940 --> 00:25:04,940
from beneath, and that is the V8 heap.
Now, in order to make sure you can collect

278
00:25:06,070 --> 00:25:10,850
these optics, you have to make tricks. And
you can see you have this pairing between

279
00:25:10,850 --> 00:25:17,430
JavaScript optics and DOM nodes by using repointers.
So, in essence, you have a JavaScript wrapper

280
00:25:17,430 --> 00:25:22,440
that points to a DOM node that in turn points
to a persistent handle &mdash; that's the black

281
00:25:22,440 --> 00:25:28,200
ones &mdash; that, in turn, will use a repointer
pointing back. So it is sort of a semicycle,

282
00:25:28,200 --> 00:25:35,200
and you break the cycle by using repointers.
So that is simple.

283
00:25:35,470 --> 00:25:41,130
But it gets even more complicated. When V8
is running out of memory and has to perform

284
00:25:41,130 --> 00:25:47,040
a garbage collection, it has to call the DOM
and ask the DOM to group all objects that

285
00:25:47,040 --> 00:25:53,930
belong together because that's needed in order
to only collect &mdash; you basically have to collect

286
00:25:53,930 --> 00:26:00,930
all grouped optics at the same time. That's
needed to avoid resurrection of wrapper optics.

287
00:26:02,290 --> 00:26:07,840
That might seem complicated, but it is needed
because if you add a property to one of the

288
00:26:07,840 --> 00:26:13,260
JavaScript nodes at the bottom and it suddenly
disappears and reappears again, the property

289
00:26:13,260 --> 00:26:19,350
is gone and the application will get a little
bit confused. So we need to do all this in

290
00:26:19,350 --> 00:26:26,350
order to make sure garbage collection works.
Did we invent this? Actually, that's the only

291
00:26:27,790 --> 00:26:34,790
thing we did. It works. Chrome is great. But
that part we are not proud of. It needs a

292
00:26:38,800 --> 00:26:44,890
lot more work in order to make sure that we
can guarantee that all memory is collected

293
00:26:44,890 --> 00:26:48,770
the right way. But we will get back to this
later in this talk, what we are doing about

294
00:26:48,770 --> 00:26:55,770
it.
Does this mean that V8 is as good as it gets?

295
00:26:57,840 --> 00:27:02,460
Right? We have taken all these techniques
from the past, advanced codebase techniques

296
00:27:02,460 --> 00:27:07,110
with hidden classes and sophisticated memory
management.

297
00:27:07,110 --> 00:27:14,110
Is this what we have, or do we want more performance?
Well, from the feedback we're getting, there's

298
00:27:14,520 --> 00:27:21,520
still a lot of bottlenecks in the browser.
Performance is not still at par with real

299
00:27:23,390 --> 00:27:27,870
languages. You can define what "real" is your
own way. But I would sort of at least say

300
00:27:27,870 --> 00:27:34,870
Java and C# as contenders.
Performance is still unpredictable. And you

301
00:27:37,220 --> 00:27:41,500
can see if you do animation in the browser,
sometimes you skip frames. And part of it

302
00:27:41,500 --> 00:27:47,100
is because you do too much compilation. Part
of it is because you do garbage collections.

303
00:27:47,100 --> 00:27:51,480
Part of it is because you are deoptimized
because suddenly the assumption changed in

304
00:27:51,480 --> 00:27:55,630
the program.
And in JavaScript, that's very easy to do

305
00:27:55,630 --> 00:28:01,550
because just jamming a lot of property on
a hot object, bam, performance changes.

306
00:28:01,550 --> 00:28:07,390
Startup is still slow. And the reason for
that is that you still have to read in the

307
00:28:07,390 --> 00:28:10,610
source code whenever you have to start up
the program.

308
00:28:10,610 --> 00:28:17,610
And, of course, JavaScript is still JavaScript.
There's a lot of implicit conversions of values

309
00:28:18,420 --> 00:28:25,420
when you run JavaScript. It is just complicated.
So having said that, the V8 project is still

310
00:28:27,470 --> 00:28:34,470
doing excellent. They are still improving
performance quarter after quarter. But we

311
00:28:34,500 --> 00:28:41,500
think that if we really want to push the performance
to the next level, something else is needed.

312
00:28:42,059 --> 00:28:47,429
Let's look at performance over time when it
comes to V8. This is a graph that shows the

313
00:28:47,429 --> 00:28:54,190
V8 benchmark score from the different versions
of Chrome, all the way up to today.

314
00:28:54,190 --> 00:29:01,190
And it's gone from 3,800 all the way up to
14,000. So it certainly has improved a lot.

315
00:29:04,630 --> 00:29:11,630
So this is great. But there's a downside.
Here's the complexity over time of V8. And

316
00:29:14,130 --> 00:29:19,840
we measure complexity by number of lines of
code in the VM.

317
00:29:19,840 --> 00:29:25,970
When we came out of V8, it was roughly 100,000
lines of code. Now it's half a million lines

318
00:29:25,970 --> 00:29:31,790
of code. And I don't know &mdash; as a programmer,
you know that there's trouble when it gets

319
00:29:31,790 --> 00:29:38,790
so big. It takes way more effort in order
to improve performance. So we question whether

320
00:29:39,360 --> 00:29:45,220
that's possible to get a factor of 2 in V8
in the near time. You can follow the graph.

321
00:29:45,220 --> 00:29:51,170
Factor of 2 will take a long time, unless
it is rewritten, of course. This also would

322
00:29:51,170 --> 00:29:56,830
be a fun project.
>>Kasper Lund: So we've gone through a lot

323
00:29:56,830 --> 00:30:03,780
of Web technology stuff here and looked into
how V8 works and why it is as fast as it is.

324
00:30:03,780 --> 00:30:10,780
Let's dive into the Dart side and look at
how Dart improves this. So Dart is a simple

325
00:30:12,870 --> 00:30:18,720
class-based unsurprising programming language.
It is designed to be very familiar so that

326
00:30:18,720 --> 00:30:23,690
Web developers and application developers
can pick it up and learn to use it in no time.

327
00:30:23,690 --> 00:30:27,410
We've got excellent feedback from users of
the system that this really works. You can

328
00:30:27,410 --> 00:30:32,860
sit down and code in Dart. And within a few
hours, you feel like you are very productive

329
00:30:32,860 --> 00:30:39,670
and it actually works out really well.
To hit that target of being very familiar,

330
00:30:39,670 --> 00:30:44,860
we've designed it based on principles and
concepts found in other languages. So the

331
00:30:44,860 --> 00:30:49,190
syntax is very much inspired by JavaScript,
Java, C#, those kind of languages. And we

332
00:30:49,190 --> 00:30:54,929
get a lot of other value from essentially
standing on the shoulders of other good programming

333
00:30:54,929 --> 00:30:58,679
languages out there and picking the things
that we feel are good fits for a language

334
00:30:58,679 --> 00:31:02,290
that needs to be really efficient and at the
same time very productive.

335
00:31:02,290 --> 00:31:07,150
One thing that we've added to Dart, which
is a little bit uncommon is support for optional

336
00:31:07,150 --> 00:31:11,480
static types. That means that you can write
static-type notations where you want them,

337
00:31:11,480 --> 00:31:15,740
where you feel like they convey the intent
that you want to convey. But you don't have

338
00:31:15,740 --> 00:31:19,960
to put them in. The system is very flexible
that way. It doesn't require you, and it is

339
00:31:19,960 --> 00:31:24,830
a fully dynamically typed system. It is hard
to describe this in one slide without showing

340
00:31:24,830 --> 00:31:30,080
some code. So I will use two.
Here is a little bit of a taste of Dart. I

341
00:31:30,080 --> 00:31:33,270
don't know how many of you are familiar with
Dart, tried it out. But for those of you who

342
00:31:33,270 --> 00:31:37,140
are seeing it for the first time, I hope you
will find that this is reasonably readable.

343
00:31:37,140 --> 00:31:43,220
It is a very simple example. It shows that
all Dart applications start with a main function.

344
00:31:43,220 --> 00:31:48,110
And in this case, I just added a little bit
of an HTML interaction here. I am creating

345
00:31:48,110 --> 00:31:54,299
a new button element, adding that to the document
body, and giving it a bit of text.

346
00:31:54,299 --> 00:31:59,179
Hopefully, you can read this code if you are
familiar with JavaScript, C#, Java, those

347
00:31:59,179 --> 00:32:02,530
kind of languages and it doesn't feel too
foreign for you. That's exactly what we wanted

348
00:32:02,530 --> 00:32:05,850
to try to get at.
One thing that might look a little bit different

349
00:32:05,850 --> 00:32:12,170
here is the import, and it just shows that
Dart has support for modularity. So you can

350
00:32:12,170 --> 00:32:17,799
import libraries of functionality and code
and use that. So we do have a namespacing

351
00:32:17,799 --> 00:32:23,780
mechanism and a way of carving up your application
in multiple independent bits. So I hope this

352
00:32:23,780 --> 00:32:30,110
seems reasonably easy to read for you guys.
I think a good question to ask at this point

353
00:32:30,110 --> 00:32:35,179
is: What are we trying to achieve with Dart?
And we feel that there is a need for a much

354
00:32:35,179 --> 00:32:40,010
more scalable development platform for Web
apps. We feel like it is too costly and too

355
00:32:40,010 --> 00:32:44,580
difficult to write great Web apps. You can
achieve amazing things on the Web today, but

356
00:32:44,580 --> 00:32:47,660
you really have to invest a lot of time in
it. Things are getting better, but we feel

357
00:32:47,660 --> 00:32:51,710
like we need something like Dart to push the
limits of this and make it much, much easier

358
00:32:51,710 --> 00:32:57,250
to write large, well-functioning applications.
We think there is a real need for higher performance

359
00:32:57,250 --> 00:33:02,929
and much faster startup. And we certainly
feel like having predictable performance where

360
00:33:02,929 --> 00:33:08,670
it's harder to write applications that really
perform poorly because of somewhat weird semantics

361
00:33:08,670 --> 00:33:14,460
in the core of the system that you're building
on is a must.

362
00:33:14,460 --> 00:33:19,190
Another thing that we consistently hear from
users of Dart and other systems is that having

363
00:33:19,190 --> 00:33:23,799
great toolability, being able to write tools
and use tools on your codebases for refactoring,

364
00:33:23,799 --> 00:33:30,190
editing, and just maneuvering around, navigating
your code is a great big help. And the static

365
00:33:30,190 --> 00:33:34,660
types that we have, even though they are optional,
they are a big help here, to just document

366
00:33:34,660 --> 00:33:39,400
your intent of your code and make use of it.
And, finally, I think it is very important

367
00:33:39,400 --> 00:33:46,400
for us that we make it easy and nice to use
a set of consistent libraries and make it

368
00:33:46,890 --> 00:33:51,350
easy for the community to create new libraries
and share them in the same way. Certainly

369
00:33:51,350 --> 00:33:56,080
an area where the Web suffered a little bit.
We see great things out there written for

370
00:33:56,080 --> 00:33:59,990
JavaScript, but it is not necessarily trivial
to make things fit together if you have multiple

371
00:33:59,990 --> 00:34:03,559
independent pieces of JavaScript functionality
you want to bring together. We are trying

372
00:34:03,559 --> 00:34:06,580
to make that better with Dart, so that's what
we are trying to achieve.

373
00:34:06,580 --> 00:34:12,710
Clearly, we want Dart to be useful in all
browsers, all modern browsers. So we've written

374
00:34:12,710 --> 00:34:18,419
a translator that translates Dart code to
JavaScript that runs in all modern browsers.

375
00:34:18,419 --> 00:34:21,840
That translator itself is actually written
in Dart, so we are trying to dogfood our own

376
00:34:21,840 --> 00:34:26,369
product here. And that has been great experience
for us, to write a fairly significant amount

377
00:34:26,369 --> 00:34:31,310
of code in Dart, translate &mdash; in a translator
that translates Dart to JavaScript can actually

378
00:34:31,310 --> 00:34:36,720
translate itself so you can take that big
piece of code and translate it to JavaScript

379
00:34:36,720 --> 00:34:42,090
and then you have a Dart-to-JavaScript translator
in JavaScript. That's kind of neat. It runs

380
00:34:42,090 --> 00:34:47,350
across all modern browsers. That's a big one
here.

381
00:34:47,350 --> 00:34:53,250
So the users that actually try using Dart
are fairly happy with some of the decisions

382
00:34:53,250 --> 00:35:00,250
we've made. And Thomas from an Austrian startup,
Blossom, describes this fairly accurately

383
00:35:00,800 --> 00:35:05,140
in one of his quotes here. He says that Dart
is exactly what he needs to be productive

384
00:35:05,140 --> 00:35:11,160
on the Web. So the feedback that we're getting
on the productivity gains of using something

385
00:35:11,160 --> 00:35:13,770
like Dart for your Web applications is very,
very positive.

386
00:35:13,770 --> 00:35:19,869
I will let this slide stay up for two more
seconds so you can read it.

387
00:35:19,869 --> 00:35:26,869
>>Lars Bak: All right. Well, for me it is
good just to have a choice of another system,

388
00:35:32,160 --> 00:35:37,180
if it fits your needs better.
But let's go a little bit deeper when it comes

389
00:35:37,180 --> 00:35:44,180
to performance. I'd like to talk about why
we can make Dart faster than JavaScript. In

390
00:35:44,869 --> 00:35:50,720
some cases, it already is.
Right. We are VM engineers. We have done that

391
00:35:50,720 --> 00:35:57,720
for most of our professional lives. And we
designed Dart to make sure we could optimize

392
00:35:57,869 --> 00:36:03,410
it. Maybe it is a little bit selfish, but
it is basically so we can get better performance.

393
00:36:03,410 --> 00:36:09,609
So the language model, the language semantics,
is very simple in Dart. It has a much simpler

394
00:36:09,609 --> 00:36:13,060
optic model.
It means that when you first have allocated

395
00:36:13,060 --> 00:36:18,240
an optic with fields, you cannot change it
after the allocation point. That's it. And

396
00:36:18,240 --> 00:36:22,820
it allows us to have much faster access to
fields, right? Just like in C# or in Java,

397
00:36:22,820 --> 00:36:28,070
you can actually access the nth element because
you know that that is exactly where the foo

398
00:36:28,070 --> 00:36:32,570
property is.
Programmers are declared so you don't have

399
00:36:32,570 --> 00:36:39,330
to run Dart in order to set up the program
in contrast to JavaScript. That allows us

400
00:36:39,330 --> 00:36:46,080
to use snapshots for having fast startup of
applications. We like that feature.

401
00:36:46,080 --> 00:36:52,100
And then we just have fewer special corner
cases to worry about. As an example of a corner

402
00:36:52,100 --> 00:36:56,350
case in JavaScript is that, well, you might
actually like it as a programmer that you

403
00:36:56,350 --> 00:37:02,490
can call a method with too many parameters
or too few. Well, this is sort of nice but

404
00:37:02,490 --> 00:37:07,100
in the implementation, somebody has to figure
out what you called it with and that costs,

405
00:37:07,100 --> 00:37:11,030
right? And if you don't provide enough argument,
somebody has to provide them for you, the

406
00:37:11,030 --> 00:37:17,180
underlying system. And stuff like that makes
the code more complicated to generate and

407
00:37:17,180 --> 00:37:24,180
the resultant code is also more loaded.
Let's give an example. Here I tried to make

408
00:37:24,260 --> 00:37:29,960
a side-by-side comparison between Dart and
JavaScript and what code it generates and

409
00:37:29,960 --> 00:37:36,600
how it works. On the right side, you can see
that we have two classes. We have a class

410
00:37:36,600 --> 00:37:43,600
A. It has a method called foo. It prints out
foo. And then we have a subclass B that inherits

411
00:37:43,780 --> 00:37:50,780
from &mdash; or extends A. It has nothing. And
you create a new B &mdash; it is called b, lowercase

412
00:37:51,369 --> 00:37:57,630
b. And the main function on the right, you
call foo. Very, very simple. We try to mimic

413
00:37:57,630 --> 00:38:02,869
the same in JavaScript. You have to go to
the left of the screen. The way we model inheritance

414
00:38:02,869 --> 00:38:09,369
in JavaScript is by using prototypes, so we
make a function A. And in the prototype of

415
00:38:09,369 --> 00:38:13,490
A, we put in the foo function, just like on
the right.

416
00:38:13,490 --> 00:38:20,490
And then we make a function B that calls constructor
A. And in the B prototype, we don't do anything.

417
00:38:22,240 --> 00:38:28,090
We just set it to a new A and then we create
a new B and we call B. So it is sort of the

418
00:38:28,090 --> 00:38:34,780
same. No difference.
The problem in JavaScript when it comes to

419
00:38:34,780 --> 00:38:41,780
speed is you can actually on the fly change
the code. So in the inserter box you can see

420
00:38:42,660 --> 00:38:48,060
that right there we actually are extending
the B pro type with a new foo that prints

421
00:38:48,060 --> 00:38:54,330
in foo. You can call B foo again. And the
semantics is you have to print out new foo

422
00:38:54,330 --> 00:39:01,119
now. We don't have that in Dart. We think
this is a plus. It is certainly a plus for

423
00:39:01,119 --> 00:39:08,119
the implementation. So let's look at it. B
is the object created. That's the object we

424
00:39:08,330 --> 00:39:15,250
wanted to execute foo on. It points to the
B prototype in JavaScript that, again, points

425
00:39:15,250 --> 00:39:21,930
to the A prototype. When you start running
the program, you don't have the middle foo

426
00:39:21,930 --> 00:39:28,100
so you have to execute the one up in A the
problem is, you don't know if somebody is

427
00:39:28,100 --> 00:39:35,100
going to insert a foo going forward. The system
has to cope with it. So in V8 you have a choice.

428
00:39:35,369 --> 00:39:41,080
Either you have to always validate. There
is no foo in the B prototype before you can

429
00:39:41,080 --> 00:39:48,080
execute the one up in A. Then it will invalidate
the code, how it generated, with these assumptions.

430
00:39:54,619 --> 00:40:00,740
The problem is, the B prototype is an ordinary
object. You do not want to put in a general

431
00:40:00,740 --> 00:40:07,740
dependency system for normal objects. So in
Dart &mdash; no, sorry, in JavaScript V8, we actually

432
00:40:09,760 --> 00:40:16,760
validate that there's no foo in the middle
here before we execute foo in the A prototype.

433
00:40:17,670 --> 00:40:24,670
That is expensive on the implementation side.
Let me try to show you what it cost in generator

434
00:40:27,950 --> 00:40:33,900
code. So given the example we had on the previous
slide, we now have a small benchmark. It's

435
00:40:33,900 --> 00:40:40,550
the micro benchmark. We don't like them, yes,
but I'm trying to make a point here. It's

436
00:40:40,550 --> 00:40:47,550
a loop that just called B.foo repeatedly.
And I warm up that program and I look at what

437
00:40:49,010 --> 00:40:54,619
the various system generates. On the left
side, you can see the result of what V8 generates.

438
00:40:54,619 --> 00:41:01,619
It generates nearly 300 bytes of common code
and 239 bytes of stop code. The stop code

439
00:41:03,530 --> 00:41:10,020
is the source. You need in order to optimization,
if something goes wrong, for instance, you

440
00:41:10,020 --> 00:41:17,020
add the extra code in the middle. On the Dart
side, it's somewhat simpler. You can see the

441
00:41:17,630 --> 00:41:24,630
optimized code here. It's much smaller. In
fact, it's only a third of the V8 code being

442
00:41:25,330 --> 00:41:31,050
generated. So the simple semantics in the
programming language just makes sense, right?

443
00:41:31,050 --> 00:41:38,050
It's much easier to make fast. Optimizing
a little bit of code is much easier than optimizing

444
00:41:39,280 --> 00:41:45,060
a big piece of code. Generally, less code
is great. Better memory performance. You also

445
00:41:45,060 --> 00:41:52,060
get predictable performance because you cannot
change the code after you start it up. So

446
00:41:52,810 --> 00:41:58,650
keep it simple. It's good for us, V8.
>>Kasper Lund: Hopefully it's very good for

447
00:41:58,650 --> 00:42:04,200
application developers that get more predictable
performance and just generally better performance.

448
00:42:04,200 --> 00:42:11,200
So let's benchmark this thing with a non-micro
brashing benchmark suite. To benchmark the

449
00:42:12,440 --> 00:42:19,440
Dart VM. We have used multiple. A couple that
are interesting are Richards and DeltaBlue.

450
00:42:25,349 --> 00:42:31,290
That means that if we make Richards and DeltaBlue
faster, it will have an impact on a real web

451
00:42:31,290 --> 00:42:38,290
application. So using benchmark that you &mdash; that
have proven valuable in the context of other

452
00:42:38,330 --> 00:42:44,700
languages makes a lot of sense, especially
if you want to try to bring a new programming

453
00:42:44,700 --> 00:42:48,780
language implementation to the web and make
sure it has nice performance properties that

454
00:42:48,780 --> 00:42:55,590
match existing real languages. So we've used
in the past for self, Strongtalk, V8, and

455
00:42:55,590 --> 00:43:02,440
now we're using these two benchmarks for tuning
Dart. It's important to stress that these

456
00:43:02,440 --> 00:43:07,119
benchmarks really measure the performance
of calling methods, memory allocation, and

457
00:43:07,119 --> 00:43:12,500
all the things applications tend to spend
a lot of time in. So Richards is an interesting

458
00:43:12,500 --> 00:43:16,660
benchmark. It's a kernel simulating benchmark
that spends a lot of time in calling small

459
00:43:16,660 --> 00:43:22,290
methods and dispatching between different
objects in here. What you see on the graph

460
00:43:22,290 --> 00:43:29,290
here is the Dart VM is on the graph. V8 is
there and DART to JS, which is the generated

461
00:43:29,840 --> 00:43:36,840
code we get from compiling the Richards version
in Dart to JavaScript with our own Compiler

462
00:43:36,930 --> 00:43:41,550
and running that on V8. So you have three
different runtime systems here in play that

463
00:43:41,550 --> 00:43:46,920
execute the same benchmark. So the Dart VM
is the fastest, which is a nice thing. You

464
00:43:46,920 --> 00:43:52,250
can see the V8 performance is getting better
but not at the same pace as the Dart VM. Bigger

465
00:43:52,250 --> 00:43:57,300
is better here. V8 has tuned for this benchmark
since its inception. We started out with a

466
00:43:57,300 --> 00:44:01,890
Richards benchmark and we have achieved a
lot of really cool speedups on these benchmarks

467
00:44:01,890 --> 00:44:08,890
over the years. It means that V8 is fairly
good at optimizing for this kind of application

468
00:44:09,380 --> 00:44:16,380
code and benchmark. The Dart VM is already
1.7 times faster than V8 generates way less

469
00:44:17,770 --> 00:44:22,930
code when running the benchmark and much better
at executing that kind of code. The Dart to

470
00:44:22,930 --> 00:44:28,119
JS code is a little bit behind. The handwritten
version of JavaScript that we use to tune

471
00:44:28,119 --> 00:44:33,230
V8 and there's some extra checks going on
in there. Something we're improving over time

472
00:44:33,230 --> 00:44:38,670
as you can see by the graph. But it's really
nice to see that over the last year, we have

473
00:44:38,670 --> 00:44:43,670
been able to take the Dart VM from being a
fairly simple implementation of a fairly simple

474
00:44:43,670 --> 00:44:50,609
language to being a really efficient implementation
of a fairly simple language. This also shows

475
00:44:50,609 --> 00:44:54,359
on the DeltaBlue benchmark numbers. Here the
difference is even bigger. It's a factor of

476
00:44:54,359 --> 00:45:00,849
2. DeltaBlue is a one-way constraint solver.
It spends time in allocating objects, constraints

477
00:45:00,849 --> 00:45:06,510
and dispatcher on them. Again, it's a benchmark
that has been used for many different languages

478
00:45:06,510 --> 00:45:12,119
and proven valuable in those context as well.
It's great to see that here the same story

479
00:45:12,119 --> 00:45:17,240
repeats itself. The Dart VM is just a lot
faster than V8. Of course, it's also faster

480
00:45:17,240 --> 00:45:22,570
than a version we compiled to JavaScript.
It's interesting to see that the Dart to JS

481
00:45:22,570 --> 00:45:26,200
numbers here are actually faster than the
handwritten JavaScript. So the comparison

482
00:45:26,200 --> 00:45:33,200
here is between handwritten JavaScript that
V8 executes, where we have tried to implement

483
00:45:33,359 --> 00:45:39,890
DeltaBlue in a reasonable way in JavaScript.
And then the generated code, this is also

484
00:45:39,890 --> 00:45:44,470
JavaScript, that we compiled from Dart code
and the reason why it's a little bit faster

485
00:45:44,470 --> 00:45:49,349
here is because we can do some analysis while
compiling. We can do some inlining to help

486
00:45:49,349 --> 00:45:55,990
V8 execute this a little bit more quickly.
We do expect this to be able to improve the

487
00:45:55,990 --> 00:46:01,880
quality of the Dart to JS Compiler over time.
We're aiming for trying to be as fast as the

488
00:46:01,880 --> 00:46:06,770
code you would have written by hand in JavaScript.
So but clearly, the Dart VM is faster in this

489
00:46:06,770 --> 00:46:11,820
kind of thing.
It's important to stress that performance

490
00:46:11,820 --> 00:46:16,210
is super important to us. It really, really
matters that you get a really scalable application

491
00:46:16,210 --> 00:46:23,210
platform out of using Dart. Having said that,
I think it's important to point to the fact

492
00:46:23,359 --> 00:46:27,359
that users of Dart are really finding that
in addition to getting good performance, they

493
00:46:27,359 --> 00:46:34,359
also feel that their productivity increased.
Ali has written a really large font atlas

494
00:46:35,040 --> 00:46:42,040
generation tool, Glyph3D. We get this feedback
fairly consistently, that people that use

495
00:46:42,710 --> 00:46:46,790
Dart for building bigger things are very,
very happy with it.

496
00:46:46,790 --> 00:46:53,790
>>Lars Bak: Thank you. Just to follow up on
what Kasper said, performance is fantastic

497
00:46:57,930 --> 00:47:03,280
in Dart right now and it's getting better
over time. We have seen on the web the last

498
00:47:03,280 --> 00:47:09,140
few weeks some examples where Dart is out
performing Java. We are super excited about

499
00:47:09,140 --> 00:47:16,140
that. We hope to get up to that level for
almost all applications basically.

500
00:47:16,150 --> 00:47:23,150
So the ultimate goal is to get the Dart VM
into Chrome. I hope you all agree. Exactly.

501
00:47:28,410 --> 00:47:29,880
At least one.
[ Laughter ]

502
00:47:29,880 --> 00:47:36,310
But we have a little bit of a problem here.
I sort of mentioned that the garbage collection

503
00:47:36,310 --> 00:47:41,000
is story where the DOM was a little bit complicated
with these reference counts and stuff like

504
00:47:41,000 --> 00:47:48,000
that. And putting Dart VM into the pit doesn't
make it easier. And we cannot convince ourselves

505
00:47:49,980 --> 00:47:56,980
with reference counting that we can reclaim
all unused cycles or memory data structures

506
00:47:57,960 --> 00:48:04,960
in the browser. That means memory leaks. We
really do not want that. So that's a problem.

507
00:48:05,030 --> 00:48:10,210
But we like to do something about it. The
ohm way we can make sure that we do something

508
00:48:10,210 --> 00:48:17,010
about it is to actually change the reference
counted nature of the DOM. And we create a

509
00:48:17,010 --> 00:48:24,010
new project, started last month. It's called
Oilpan. It makes sure that it handles garbage

510
00:48:24,720 --> 00:48:30,250
collection between the difference segments
inside Chrome and Blink. Which is JavaScript,

511
00:48:30,250 --> 00:48:37,250
DOM, eventually Dart. We want to convert the
reference count in DOM into being traced so

512
00:48:40,030 --> 00:48:45,380
we can trace through JavaScript ons, through
DOM nodes and through Dart nodes and make

513
00:48:45,380 --> 00:48:51,880
sure we know what we have. The cool thing
about tracing is you can find all pointers

514
00:48:51,880 --> 00:48:57,250
that point to an object. That means you can
move the object if you choose to do so. You

515
00:48:57,250 --> 00:49:04,250
can even do [indiscernible] and start from
that point on. And if you are really brave,

516
00:49:10,640 --> 00:49:17,000
we can start doing concurrent manipulation
of the DOM. So we hope this is all appealing

517
00:49:17,000 --> 00:49:22,000
for us guys because it basically means we
get a much faster browser out of it and a

518
00:49:22,000 --> 00:49:29,000
browser use less memory. One thing about the
con currency when you have reference counting

519
00:49:29,820 --> 00:49:35,250
in the objects, you actually have to put in
a lock around it if you do concurrent access.

520
00:49:35,250 --> 00:49:41,240
That's expensive. When you get a pointer to
an object, you have to lock, increment the

521
00:49:41,240 --> 00:49:45,170
pointer, unlock again. That's not practical
when using reference counting. We can do all

522
00:49:45,170 --> 00:49:52,170
this if unify the memory manager for playing.
We are excited about this project.

523
00:49:52,500 --> 00:49:59,220
>>Kasper Lund: We feel like no presentation
is really done without a demo of some sort.

524
00:49:59,220 --> 00:50:05,880
So lately we have been working on making Dart
even faster. No surprise there. A lot of modern

525
00:50:05,880 --> 00:50:10,660
CPUs today support what is known as SIMD,
single instruction multi-data instructions,

526
00:50:10,660 --> 00:50:16,980
where you have instructions on the CPU that
can operate on four floating point values

527
00:50:16,980 --> 00:50:21,800
in parallel making it much, much faster. So
the Dart VM has been enhanced for support

528
00:50:21,800 --> 00:50:27,099
for using those instructions and no other
web language has the support yet. It's very

529
00:50:27,099 --> 00:50:32,680
nice to see this in action in a browser, just
making things faster. It's really useful for

530
00:50:32,680 --> 00:50:39,020
3D calculations, image processing, audio processing.
We would like to show you a little demo of

531
00:50:39,020 --> 00:50:45,839
Google Chrome with the Dart VM put in there
running a 3D animation thing with and without

532
00:50:45,839 --> 00:50:50,880
the SIMD support to show you the significance
of this kind of work. So let's switch to the

533
00:50:50,880 --> 00:50:57,880
other.
>>Lars Bak: So here we are running Dart VM

534
00:51:01,960 --> 00:51:08,960
with a Blink with Dart VM. We have a bunch
of monsters. They all handle inside Dart.

535
00:51:09,550 --> 00:51:15,160
So that means that the animation, the skeleton
positions and all that is happening inside

536
00:51:15,160 --> 00:51:22,160
Dart. It's not on the GPU. And this is the
&mdash; somebody is beeping. This benchmark has

537
00:51:25,500 --> 00:51:31,670
been created so it is trying to always have
60 frames per second. If it runs too fast,

538
00:51:31,670 --> 00:51:38,670
it will throw in more monsters. We have 34.
We can turn it on with using a flag down here.

539
00:51:45,880 --> 00:51:52,880
Let's try it. SIMD. So this is using SIMD
in animation in Dart.

540
00:52:00,970 --> 00:52:05,390
[ Applause ]
So a factor of three and a half is not too

541
00:52:05,390 --> 00:52:12,390
bad, I guess. I'm really excited about this
and it actually gives you a lot more power

542
00:52:12,430 --> 00:52:19,430
to do computation inside JavaScript. So this
is coming to you and I'm excited.

543
00:52:20,040 --> 00:52:27,040
>>Kasper Lund: So let's conclude this presentation
so we have time for some questions. So we

544
00:52:33,330 --> 00:52:39,670
are VM guys. We want to have a job moving
forward. We think performance is always interesting.

545
00:52:39,670 --> 00:52:46,210
I hope you like that, too. And we hope we
have convinced you that if you really want

546
00:52:46,210 --> 00:52:53,210
to spark more performance into the browser,
we need probably a different option than JavaScript.

547
00:52:53,280 --> 00:53:00,280
I think Dart is one contender for that. The
Dart VM is already faster than JavaScript

548
00:53:01,880 --> 00:53:08,500
and is approaching other programming languages
out there. Again, just to point it out again

549
00:53:08,500 --> 00:53:13,540
that higher performance is great for application
developers. That's where you actually can

550
00:53:13,540 --> 00:53:20,540
get head room to do more interesting stuff.
Right now, the core Dart platform is stable.

551
00:53:21,260 --> 00:53:28,260
We will start using the SDK. That doesn't
mean it's inside Chrome. After we send out

552
00:53:29,480 --> 00:53:36,480
1.0, that will be our main focus. Right now
you can see people on the web using Dart.

553
00:53:36,760 --> 00:53:43,420
Some have written fairly large bodies of code
and they are happy with it. And inside Google

554
00:53:43,420 --> 00:53:49,570
people have started using it. There's critical
projects start using Dart, hopefully we will

555
00:53:49,570 --> 00:53:56,030
see some of these applications coming to you
soon. This will conclude our presentation.

556
00:53:56,030 --> 00:54:01,720
We should go to questions.
[ Applause ]

557
00:54:01,720 --> 00:54:08,720
>>Kasper Lund: If we are unable to answer
your questions here. We have other Dart questions

558
00:54:13,920 --> 00:54:18,960
at Google I/O today. So if you have found
this inspiring and you want to see more on

559
00:54:18,960 --> 00:54:24,480
more specific details, here's a list of things
in room &mdash; mostly in room 6, I guess, where

560
00:54:24,480 --> 00:54:28,060
you can see other Dart presentations here.
Yes?

561
00:54:28,060 --> 00:54:33,930
>>Lars Bak: Let's get the first question.
>>> My question is slightly related to that

562
00:54:33,930 --> 00:54:39,560
first one, coming from a GWT development background,
wondering if you have done any benchmarks

563
00:54:39,560 --> 00:54:46,170
in comparison from the Dart to JavaScript
Compiler to the Java to JavaScript Compiler.

564
00:54:46,170 --> 00:54:53,170
>>Lars Bak: I don't have any numbers for you.
It is easy to try out. DeltaBlue, it is free

565
00:54:54,770 --> 00:55:01,770
to try out for yourself. One thing I would
like to see is that we are trying to go beyond

566
00:55:08,119 --> 00:55:15,119
grit in that we are doing a native Dart VM
that can boost performance and reduce startup

567
00:55:15,500 --> 00:55:20,770
time. This is really what we want to get at.
Especially for mobile platforms where loading

568
00:55:20,770 --> 00:55:26,470
an application can be a dog and take many
resources. Faster VM, faster startup means

569
00:55:26,470 --> 00:55:33,140
less battery. Next question, please.
>>> Hi. Have there been discussions of including

570
00:55:33,140 --> 00:55:39,369
Dart in other browsers and if not, would it
be possible to add it through plug-ins?

571
00:55:39,369 --> 00:55:46,369
>>Lars Bak: It will be fantastic to have all
browsers using Dart. Clearly people have strong

572
00:55:51,510 --> 00:55:55,430
opinions when it comes to programming languages.
I don't really understand why but that's how

573
00:55:55,430 --> 00:55:58,000
it is.
[ Laughter ]

574
00:55:58,000 --> 00:56:03,349
I just want to make sure that people the right
tools to build the applications with. Our

575
00:56:03,349 --> 00:56:08,400
system is completely open source. It has a
well-defined API. So when other browsers think

576
00:56:08,400 --> 00:56:12,960
that this extra boost of performance will
be good for them, they can take it up and

577
00:56:12,960 --> 00:56:17,570
we will be happy to help them out, basically.
So we are open for collaboration.

578
00:56:17,570 --> 00:56:23,780
>>Kasper Lund: We have a few questions from
our online audience and maybe just try to

579
00:56:23,780 --> 00:56:28,300
answer a few of them as well. I can cover
the second one. I think you covered the grit

580
00:56:28,300 --> 00:56:34,220
question already. This question is about Android
studio. And if we are planning on releasing

581
00:56:34,220 --> 00:56:39,619
something similar for Dart. In a sense we
already are releasing something similar for

582
00:56:39,619 --> 00:56:45,750
Dart. We have a fully-featured Dart editor.
But in addition to that, and maybe this is

583
00:56:45,750 --> 00:56:49,579
what the question is really about, we do have
support for using and working with Dart from

584
00:56:49,579 --> 00:56:56,500
IntelliJ. It is here. If you are interested
in this kind of thing, definitely come talk

585
00:56:56,500 --> 00:57:01,619
to them at the booth. So the short answer
is really that we are looking into releasing

586
00:57:01,619 --> 00:57:06,099
all sorts of nice tools for Dart being based
both on Eclipse and IntelliJ. Definitely.

587
00:57:06,099 --> 00:57:09,450
>>Lars Bak: Let's take the next question from
the audience.

588
00:57:09,450 --> 00:57:15,829
>>> Hi. I have a bit of long &mdash; seemingly
longstanding wisdom I got a few years ago

589
00:57:15,829 --> 00:57:21,079
that occurs to me might be out of date which
is the idea &mdash; this is about V8, that JavaScript

590
00:57:21,079 --> 00:57:26,410
objects are going to be more performant if
you define prototype rather than defining

591
00:57:26,410 --> 00:57:32,359
methods dynamically in a constructor. It occurs
to me with hidden, you have optimized it so

592
00:57:32,359 --> 00:57:39,310
it wouldn't make a difference.
>>Lars Bak: We certainly try to. We tried

593
00:57:39,310 --> 00:57:46,230
very hard to optimize in V8. But it's still
the case that you have to create a new class

594
00:57:46,230 --> 00:57:52,920
whenever you add a property in a way you haven't
seen before. So you get a forest of classes

595
00:57:52,920 --> 00:57:59,880
even for the same constructor. And in Dart,
you only have one format for one class whereas

596
00:57:59,880 --> 00:58:06,160
in V8, right, depending on how you add properties
to an object from a given constructor, you

597
00:58:06,160 --> 00:58:10,920
can get a sea of them. We have to cut off
at some point. We have limits inside V8. When

598
00:58:10,920 --> 00:58:16,549
you reach a certain number of hidden classes
for constructer. We say, we actually just

599
00:58:16,549 --> 00:58:23,549
&mdash; we de-optimize now and we make sure that
objects will only be treated as maps and get

600
00:58:24,369 --> 00:58:27,010
slow.
>>> So is it true that, then, prototype would

601
00:58:27,010 --> 00:58:32,940
be more performant in V8 than using construct-defining
properties, even if you define them the same

602
00:58:32,940 --> 00:58:36,970
way every time in constructor.
>>Lars Bak: I think it depends on exactly

603
00:58:36,970 --> 00:58:41,560
the setup. You can make it so they perform
exactly the same. It really depends on how

604
00:58:41,560 --> 00:58:46,380
the application adds properties to your object
on the fly.

605
00:58:46,380 --> 00:58:52,589
>>Kasper Lund: Little bit of explanation.
V8 does try to move functions to the class

606
00:58:52,589 --> 00:58:57,020
side so to share them behind the scenes anyway.
So you can say adding on the objects is sort

607
00:58:57,020 --> 00:59:02,070
of optimize too, but it really depends on
the application if it makes a difference.

608
00:59:02,070 --> 00:59:06,619
>>Lars Bak: Next question.
>>> One of the arguments for no JS is that

609
00:59:06,619 --> 00:59:11,210
you have JavaScript everywhere, service side
even. Are you looking at Dart service side

610
00:59:11,210 --> 00:59:16,560
or is there more momentum behind go.
>>Lars Bak: That's a great question. Of course,

611
00:59:16,560 --> 00:59:23,560
we have that. So we have a service side library
you can use. You can use the Dart VM stand

612
00:59:25,640 --> 00:59:30,920
alone if you want to. You can use the same
kind of ace synchronize size style as you

613
00:59:30,920 --> 00:59:37,920
do in no JS. You saw the performance numbers
on the slide. This is a performance measurement

614
00:59:38,800 --> 00:59:45,300
system we are using internally, all written
in Dart. It controls a lot of machines at

615
00:59:45,300 --> 00:59:52,300
the same time we use exactly that server side
system. So, yes, we have a libraries for supporting

616
00:59:54,450 --> 01:00:00,190
service side Dart execution but our main focus
right now is the client side and getting it

617
01:00:00,190 --> 01:00:02,530
to Chrome.
>>Kasper Lund: I think we have time for one

618
01:00:02,530 --> 01:00:08,339
more question. If you have more questions,
the large line, it will be at the office hours

619
01:00:08,339 --> 01:00:14,170
booth so come to us and ask those questions
there. But let's take the final question.

620
01:00:14,170 --> 01:00:19,290
>>> My question is there's a lot of JavaScript
code already there. Is there a tool, or even

621
01:00:19,290 --> 01:00:22,369
if it is possible, to convert JavaScript into
Dart.

622
01:00:22,369 --> 01:00:27,940
>>Kasper Lund: Generally we find that people
that try to rewrite existing code basis from

623
01:00:27,940 --> 01:00:32,260
JavaScript or from other languages to Dart
are generally fairly successful. It's also

624
01:00:32,260 --> 01:00:36,940
possible to use the JavaScript code from Dart
by wrapping it a little bit and using what

625
01:00:36,940 --> 01:00:43,260
we called JavaScript interrupt. But generally
translating from JavaScript, unless you use

626
01:00:43,260 --> 01:00:48,810
very, very dynamic features of JavaScript
a lot, it's actually recently easy. A lot

627
01:00:48,810 --> 01:00:51,960
of people have good success with that.
>>> You guys have a tool.

628
01:00:51,960 --> 01:00:57,859
>>Kasper Lund: There is no tool, no.
>>Lars Bak: Thank you very much.

629
01:00:57,859 --> 01:00:58,130
[ Applause ]

