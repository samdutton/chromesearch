1
00:00:00,000 --> 00:00:01,010

2
00:00:01,010 --> 00:00:01,620
JOSH ESTELLE: All right.

3
00:00:01,620 --> 00:00:03,360
Good morning, everybody.

4
00:00:03,360 --> 00:00:05,000
Thanks for coming.

5
00:00:05,000 --> 00:00:06,820
So my name's Josh Estelle.

6
00:00:06,820 --> 00:00:07,975
I'm a software engineer.

7
00:00:07,975 --> 00:00:09,840
I work on Google Translate.

8
00:00:09,840 --> 00:00:12,380
I've been working on that for
about seven years, and I lead

9
00:00:12,380 --> 00:00:14,730
our frontend and mobile teams.

10
00:00:14,730 --> 00:00:16,420
Today, we're going to talk to
you about Google Translate.

11
00:00:16,420 --> 00:00:18,630
And this is my colleague, Rohit,
who's going to talk to

12
00:00:18,630 --> 00:00:21,470
you about the API towards the
second half of the talk.

13
00:00:21,470 --> 00:00:26,120

14
00:00:26,120 --> 00:00:27,240
We're going to talk
about why machine

15
00:00:27,240 --> 00:00:28,790
translation is important.

16
00:00:28,790 --> 00:00:31,830
We're going to talk about how
Google Translate works, and

17
00:00:31,830 --> 00:00:34,190
then we're going to talk
about the API.

18
00:00:34,190 --> 00:00:36,345
So the first thing I always like
to express to people is

19
00:00:36,345 --> 00:00:38,120
that translation is hard.

20
00:00:38,120 --> 00:00:39,770
This is not an easy task.

21
00:00:39,770 --> 00:00:40,930
Forget about computers.

22
00:00:40,930 --> 00:00:42,400
Forget about machines.

23
00:00:42,400 --> 00:00:45,600
Just translating is
hard, even for us.

24
00:00:45,600 --> 00:00:48,610
Even for the most multilingual,
most talented

25
00:00:48,610 --> 00:00:51,670
linguists, translation is
a time-consuming task.

26
00:00:51,670 --> 00:00:53,000
It takes a lot of energy.

27
00:00:53,000 --> 00:00:55,360
It takes a lot of domain
knowledge.

28
00:00:55,360 --> 00:00:57,080
This is a tough task.

29
00:00:57,080 --> 00:00:59,970
So I like to really get that
out there before we kind of

30
00:00:59,970 --> 00:01:02,320
get into teaching machines
to do that tough task.

31
00:01:02,320 --> 00:01:06,200
This is already a hard
task for humans.

32
00:01:06,200 --> 00:01:09,600
But at Google, we like
hard problems.

33
00:01:09,600 --> 00:01:10,730
And I'm really proud
that we're able

34
00:01:10,730 --> 00:01:12,270
to tackle this problem.

35
00:01:12,270 --> 00:01:15,360
But we're not the first.

36
00:01:15,360 --> 00:01:18,520
About 60 years ago, people
were already trying to do

37
00:01:18,520 --> 00:01:19,820
machine translation.

38
00:01:19,820 --> 00:01:23,430
A lot of people argue that
translation was actually the

39
00:01:23,430 --> 00:01:26,650
first non-numerical task that
people tried to apply

40
00:01:26,650 --> 00:01:27,710
computers to, right?

41
00:01:27,710 --> 00:01:31,290
Before that, it was all
numerical calculations.

42
00:01:31,290 --> 00:01:32,920
And this was still in the early
days of computing, but

43
00:01:32,920 --> 00:01:35,925
they were already starting
about doing translation.

44
00:01:35,925 --> 00:01:39,410
And at Georgetown, with a joint
project with IBM, they

45
00:01:39,410 --> 00:01:42,290
started a project to do
machine translation.

46
00:01:42,290 --> 00:01:45,710
In 1954, they did a public
demonstration.

47
00:01:45,710 --> 00:01:48,910
Their demonstration was on the
IBM 701, which was the first

48
00:01:48,910 --> 00:01:50,690
commercially-available
mainframe.

49
00:01:50,690 --> 00:01:53,260
This was a big, old, slow
computer, but they did

50
00:01:53,260 --> 00:01:55,190
translation on it.

51
00:01:55,190 --> 00:01:56,660
Their system was very simple.

52
00:01:56,660 --> 00:02:01,080
It had 250 vocabulary words and
six rules of grammar, and

53
00:02:01,080 --> 00:02:03,250
their demo only did
60 sentences

54
00:02:03,250 --> 00:02:05,470
from Russian to English.

55
00:02:05,470 --> 00:02:07,990
Simple system, but really
impressed the public.

56
00:02:07,990 --> 00:02:09,730
This really got people
excited and engaged.

57
00:02:09,730 --> 00:02:12,170
And they were like, wow, these
amazing computer things.

58
00:02:12,170 --> 00:02:14,240
They can do translation.

59
00:02:14,240 --> 00:02:17,650
And tons of excitement, national
media coverage, and

60
00:02:17,650 --> 00:02:24,090
it really excited the research
going on at that time.

61
00:02:24,090 --> 00:02:26,910
And they predicted that they
would solve translation within

62
00:02:26,910 --> 00:02:27,990
three to five years.

63
00:02:27,990 --> 00:02:30,510
Three to five years, we'll
have this thing done.

64
00:02:30,510 --> 00:02:33,880
Anyone who works on translation
now or has used

65
00:02:33,880 --> 00:02:36,620
machine translation probably
realizes we didn't quite get

66
00:02:36,620 --> 00:02:38,470
there in three to five years.

67
00:02:38,470 --> 00:02:40,730
But we're getting closer.

68
00:02:40,730 --> 00:02:42,425
There's been a lot of good
research and a lot of things

69
00:02:42,425 --> 00:02:46,120
that have happened, especially
in the past 10 to 15 years,

70
00:02:46,120 --> 00:02:49,670
that are getting us
a long ways along.

71
00:02:49,670 --> 00:02:51,900
The first big one is
computational power.

72
00:02:51,900 --> 00:02:54,240
I don't have to tell this
audience what's the amazing

73
00:02:54,240 --> 00:02:57,530
things that we can do with
computers these days, and

74
00:02:57,530 --> 00:02:59,970
especially comparing
to that IBM 701.

75
00:02:59,970 --> 00:03:03,340
That machine could do two
multiplications every second.

76
00:03:03,340 --> 00:03:05,790
The phones in our pockets
can do billions of

77
00:03:05,790 --> 00:03:07,070
computations a second.

78
00:03:07,070 --> 00:03:10,110
And for Google Translate, we
use data centers full of

79
00:03:10,110 --> 00:03:13,180
machines with amazing
computational power.

80
00:03:13,180 --> 00:03:16,340
The second piece we have now
is data, tons of data.

81
00:03:16,340 --> 00:03:21,150
We train our system off all the
content on the web, right?

82
00:03:21,150 --> 00:03:22,260
Think of how big that is.

83
00:03:22,260 --> 00:03:24,460
Think about how many documents
are out there.

84
00:03:24,460 --> 00:03:27,460
We use all of it to build
the translation system.

85
00:03:27,460 --> 00:03:30,110
And then the last bit is where
research has come.

86
00:03:30,110 --> 00:03:32,560
This is academic research,
industry research.

87
00:03:32,560 --> 00:03:35,450
We've benefited from all that,
and we write our papers back

88
00:03:35,450 --> 00:03:36,930
to that community as well.

89
00:03:36,930 --> 00:03:39,150
But it has led to statistical
machine translation, which is

90
00:03:39,150 --> 00:03:42,140
a different approach to
translation than that

91
00:03:42,140 --> 00:03:44,590
rules-based system
of 50 years ago.

92
00:03:44,590 --> 00:03:46,850
Rules-based machine translation
uses grammar

93
00:03:46,850 --> 00:03:49,650
rules, and you try to hard
code those rules into a

94
00:03:49,650 --> 00:03:52,680
computer and then run some
code that follows them.

95
00:03:52,680 --> 00:03:54,680
Statistical machine translation
uses statistics

96
00:03:54,680 --> 00:03:57,080
and probability to learn
language and learn how to

97
00:03:57,080 --> 00:03:59,220
translations work from
lots of examples.

98
00:03:59,220 --> 00:04:01,530
And I'll tell you more
about that later.

99
00:04:01,530 --> 00:04:04,560
So let's get to Google
Translate.

100
00:04:04,560 --> 00:04:06,590
So Google's mission, I hope
many of you know, is to

101
00:04:06,590 --> 00:04:08,190
organize the world's information
and make it

102
00:04:08,190 --> 00:04:10,450
universally accessible
and useful.

103
00:04:10,450 --> 00:04:13,460
That piece of being universally
accessible, we see

104
00:04:13,460 --> 00:04:16,640
machine translation as an,
essential part of that.

105
00:04:16,640 --> 00:04:18,899
Without machine translation,
there's tons of content out in

106
00:04:18,899 --> 00:04:20,600
the world that you're never
going to be able to

107
00:04:20,600 --> 00:04:21,440
understand.

108
00:04:21,440 --> 00:04:24,460
Now we're mostly English
speaking here, right, so we

109
00:04:24,460 --> 00:04:25,870
maybe don't see this
as big a problem.

110
00:04:25,870 --> 00:04:28,750
But we think about our
colleagues in China and Tokyo

111
00:04:28,750 --> 00:04:34,740
and other places that have less
internet penetration, and

112
00:04:34,740 --> 00:04:36,470
most of the internet is
not accessible to

113
00:04:36,470 --> 00:04:37,810
them in their language.

114
00:04:37,810 --> 00:04:39,290
So we think that machine
translation can

115
00:04:39,290 --> 00:04:42,110
really enable that.

116
00:04:42,110 --> 00:04:45,360
So let's get into a little
history of Google Translate.

117
00:04:45,360 --> 00:04:48,520
All the way back in 2001, we had
our first system launch.

118
00:04:48,520 --> 00:04:52,290
This was a third-party system
that we licensed, but this was

119
00:04:52,290 --> 00:04:54,330
just three years after
Google was founded.

120
00:04:54,330 --> 00:04:58,300
Larry and Sergey saw that need
for machine translation.

121
00:04:58,300 --> 00:05:00,740
We had five languages initially
and then a couple

122
00:05:00,740 --> 00:05:03,690
years later added a few more,
but all still licensed

123
00:05:03,690 --> 00:05:04,990
third-party technology.

124
00:05:04,990 --> 00:05:08,220
This technology was
state-of-the-art at the time,

125
00:05:08,220 --> 00:05:10,020
but it was still that
rules-based machine

126
00:05:10,020 --> 00:05:10,980
translation &mdash;

127
00:05:10,980 --> 00:05:12,880
not all that different
from the Georgetown

128
00:05:12,880 --> 00:05:14,830
experiment 60 years ago.

129
00:05:14,830 --> 00:05:17,170
It improved, had definitely
gotten better, but still

130
00:05:17,170 --> 00:05:19,390
wasn't that great.

131
00:05:19,390 --> 00:05:24,090
So then in 2003, we started
taking a Google approach to

132
00:05:24,090 --> 00:05:26,830
machine translation, to using
lots of data and lots of

133
00:05:26,830 --> 00:05:29,230
computational power.

134
00:05:29,230 --> 00:05:31,020
Think about how web search
works, right?

135
00:05:31,020 --> 00:05:33,810
We use all that content on the
web, all the links between

136
00:05:33,810 --> 00:05:37,080
pages, and from that we try to
find good search results.

137
00:05:37,080 --> 00:05:39,040
We wanted to try the same
thing for translation &mdash;

138
00:05:39,040 --> 00:05:41,510
use all those documents out on
the web, all those sentences,

139
00:05:41,510 --> 00:05:43,840
all those translations, and
see if we could learn from

140
00:05:43,840 --> 00:05:46,790
that data and come up with
good translations.

141
00:05:46,790 --> 00:05:48,620
We weren't sure this
would work.

142
00:05:48,620 --> 00:05:51,580
But then two years later, we
participated in the NIST

143
00:05:51,580 --> 00:05:53,090
Machine Translation
evaluation.

144
00:05:53,090 --> 00:05:56,620
NIST is the National Institute
for Standards and Technology.

145
00:05:56,620 --> 00:05:58,230
And we were pleasantly surprised
that our system

146
00:05:58,230 --> 00:05:59,130
really worked.

147
00:05:59,130 --> 00:06:03,450
We outperformed all the other
competitors evaluated at that

148
00:06:03,450 --> 00:06:06,570
evaluation, and we were really
proud of our system.

149
00:06:06,570 --> 00:06:09,460
It proved our data-driven
approach could work and

150
00:06:09,460 --> 00:06:12,120
established us as a leader
in the field.

151
00:06:12,120 --> 00:06:14,670
Although at that time, our
research system, we only

152
00:06:14,670 --> 00:06:17,310
translated 1,000 sentences for
that competition, and it took

153
00:06:17,310 --> 00:06:19,510
us 40 hours to translate them.

154
00:06:19,510 --> 00:06:21,740
You can imagine just a single
web page might have 1,000

155
00:06:21,740 --> 00:06:24,590
sentences, and we translate
many of those now.

156
00:06:24,590 --> 00:06:25,700
So this was way too slow.

157
00:06:25,700 --> 00:06:27,140
We needed to make this fast.

158
00:06:27,140 --> 00:06:29,940
So that was the next thing we
worked towards, and it took us

159
00:06:29,940 --> 00:06:33,410
a couple more years before
we launched in 2006.

160
00:06:33,410 --> 00:06:35,450
The first languages that we
launched were Chinese and

161
00:06:35,450 --> 00:06:39,680
Arabic, and then a little later
that year, Russian.

162
00:06:39,680 --> 00:06:41,640
So we kept going from there.

163
00:06:41,640 --> 00:06:45,830
Here's a little slide of
all of our languages.

164
00:06:45,830 --> 00:06:48,980
2007, we launched nine more,
and we replaced that

165
00:06:48,980 --> 00:06:49,790
third-party system.

166
00:06:49,790 --> 00:06:52,590
So now it was completely
our own technology.

167
00:06:52,590 --> 00:06:55,790
2008, another 21 languages.

168
00:06:55,790 --> 00:06:59,860
And the big deal that year was
before 2008, we couldn't

169
00:06:59,860 --> 00:07:01,140
translate to any other language

170
00:07:01,140 --> 00:07:02,100
besides English, right?

171
00:07:02,100 --> 00:07:05,910
So Arabic to English, Chinese to
English, French to English.

172
00:07:05,910 --> 00:07:07,920
In 2008, now you could translate
between any of our

173
00:07:07,920 --> 00:07:08,700
languages, right?

174
00:07:08,700 --> 00:07:12,340
So you could go Vietnamese to
Greek and then to Serbian to

175
00:07:12,340 --> 00:07:15,360
Slovak, and go between any of
the languages we support.

176
00:07:15,360 --> 00:07:18,440
We kept going from there,
launching lots more languages.

177
00:07:18,440 --> 00:07:20,900
In 2011, we launched the
commercial API that we're

178
00:07:20,900 --> 00:07:22,640
going to talk about later.

179
00:07:22,640 --> 00:07:27,020
And now in 2013, my slide says
66 languages, and that's

180
00:07:27,020 --> 00:07:27,560
what's listed there.

181
00:07:27,560 --> 00:07:30,230
But I crossed it out, because
the beauty of continuing to

182
00:07:30,230 --> 00:07:32,170
launch new languages is
my slides get out

183
00:07:32,170 --> 00:07:33,620
of date really fast.

184
00:07:33,620 --> 00:07:35,340
So I added this new slide.

185
00:07:35,340 --> 00:07:38,750
We're now up to 71 languages,
just as of a

186
00:07:38,750 --> 00:07:40,280
week and a half ago.

187
00:07:40,280 --> 00:07:42,680
And the last five languages we
just launched are Bosnian,

188
00:07:42,680 --> 00:07:44,210
Cebuano, Hmong, Javanese,
and Marathi.

189
00:07:44,210 --> 00:07:46,970

190
00:07:46,970 --> 00:07:49,080
So you see that we're starting
to get into languages that

191
00:07:49,080 --> 00:07:52,080
really have a much smaller
amount of speakers out in the

192
00:07:52,080 --> 00:07:54,980
world and much less data, which
is a big challenge for

193
00:07:54,980 --> 00:07:58,440
us to get enough data to
build these systems.

194
00:07:58,440 --> 00:07:59,420
So that's a little
of the history.

195
00:07:59,420 --> 00:08:03,780
Let me get a little deeper
into how things work.

196
00:08:03,780 --> 00:08:09,470
So people and machines, we
learn to translate very

197
00:08:09,470 --> 00:08:11,250
differently than each
other, right?

198
00:08:11,250 --> 00:08:14,240
So when humans learn to
translate or learn another

199
00:08:14,240 --> 00:08:16,400
language, we learn
some vocabulary.

200
00:08:16,400 --> 00:08:18,060
We start learning those
grammar rules.

201
00:08:18,060 --> 00:08:20,430
We learn the exceptions to the
rules, the exceptions to the

202
00:08:20,430 --> 00:08:22,280
exceptions, and the exception
to the exceptions to the

203
00:08:22,280 --> 00:08:23,420
exceptions, and so on.

204
00:08:23,420 --> 00:08:27,810
Anyone who's learned another
language knows what I mean.

205
00:08:27,810 --> 00:08:29,760
With statistical machine
translation, that's not how

206
00:08:29,760 --> 00:08:30,420
computers learn.

207
00:08:30,420 --> 00:08:32,940
They just see lots and
lots of examples.

208
00:08:32,940 --> 00:08:36,030
It's like just trying to read
hundreds of thousands of books

209
00:08:36,030 --> 00:08:38,600
in two languages and just coming
out at the end and

210
00:08:38,600 --> 00:08:40,620
knowing that language.

211
00:08:40,620 --> 00:08:42,809
So instead of describing exactly
how that works, I'm

212
00:08:42,809 --> 00:08:44,460
going to try to teach
you how to learn the

213
00:08:44,460 --> 00:08:46,460
way a computer does.

214
00:08:46,460 --> 00:08:49,780
So I'm going to start
with this example.

215
00:08:49,780 --> 00:08:51,100
This is a Chinese menu, right?

216
00:08:51,100 --> 00:08:55,220
We've got some soups, and this
menu has both the English menu

217
00:08:55,220 --> 00:08:57,920
item and then the Chinese
for the same menu item.

218
00:08:57,920 --> 00:09:02,410
This is a single parallel
example of text.

219
00:09:02,410 --> 00:09:04,980
And if you look at the one
highlighted there, you can see

220
00:09:04,980 --> 00:09:08,600
"egg drop" only appears in the
English text in three of the

221
00:09:08,600 --> 00:09:11,300
items, and then we can find that
Chinese character that

222
00:09:11,300 --> 00:09:14,460
only appears in those
same three items.

223
00:09:14,460 --> 00:09:16,480
Now, I don't know for sure that
Chinese character means

224
00:09:16,480 --> 00:09:18,170
"egg drop," but I think
it does, right?

225
00:09:18,170 --> 00:09:19,465
It seems a good correspondence.

226
00:09:19,465 --> 00:09:21,100
It probably does.

227
00:09:21,100 --> 00:09:22,180
What about "chicken"?

228
00:09:22,180 --> 00:09:25,340
So can you guys figure out
which character means

229
00:09:25,340 --> 00:09:29,720
"chicken?" Raise your hand
once you figure it out.

230
00:09:29,720 --> 00:09:30,230
OK, OK.

231
00:09:30,230 --> 00:09:30,870
Good.

232
00:09:30,870 --> 00:09:32,890
Yeah, so you don't know Chinese,
but now you know the

233
00:09:32,890 --> 00:09:35,800
Chinese character for
"chicken," right?

234
00:09:35,800 --> 00:09:38,315
So there it is for you,
for those of you who

235
00:09:38,315 --> 00:09:40,120
are a little slower.

236
00:09:40,120 --> 00:09:41,770
This also works for
phrases, right?

237
00:09:41,770 --> 00:09:45,360
So "corn cream" aligns to these
two Chinese characters.

238
00:09:45,360 --> 00:09:47,970
And my first example, right,
was "egg drop," two English

239
00:09:47,970 --> 00:09:51,340
words to a single Chinese
character.

240
00:09:51,340 --> 00:09:52,190
And then what about "soup"?

241
00:09:52,190 --> 00:09:55,080
Can you find the Chinese
character for "soup"?

242
00:09:55,080 --> 00:09:57,690
Yeah, so that one's a little
bit interesting.

243
00:09:57,690 --> 00:09:59,700
So there's "soup."

244
00:09:59,700 --> 00:10:03,590
But you'll notice in menu item
60, on the English side we say

245
00:10:03,590 --> 00:10:06,530
"Cantonese wonton soup," but on
the Chinese side, we don't

246
00:10:06,530 --> 00:10:11,290
see that character for "soup."
And then on 65, on the English

247
00:10:11,290 --> 00:10:14,380
side, "egg drop wonton mix," but
then on the Chinese side,

248
00:10:14,380 --> 00:10:16,020
we do have the character
for "soup."

249
00:10:16,020 --> 00:10:18,080
So this shows that even in
situations where the

250
00:10:18,080 --> 00:10:21,940
translations aren't precisely,
exactly the same word-for-word

251
00:10:21,940 --> 00:10:24,090
kinds of things that we can
still learn that that

252
00:10:24,090 --> 00:10:27,470
character means "soup," even
though it doesn't always work.

253
00:10:27,470 --> 00:10:29,900
That's how a statistical
system works, right?

254
00:10:29,900 --> 00:10:32,340
We learn all these probabilities
of translations

255
00:10:32,340 --> 00:10:33,590
and that sort of thing.

256
00:10:33,590 --> 00:10:37,730

257
00:10:37,730 --> 00:10:39,350
So that was one document.

258
00:10:39,350 --> 00:10:40,960
We need a lot more than
one document, right?

259
00:10:40,960 --> 00:10:44,180
We need billions and billions
and billions of documents.

260
00:10:44,180 --> 00:10:46,850
And the kind of documents we use
are less so like a Chinese

261
00:10:46,850 --> 00:10:49,020
menu where both texts are
there, and they're more

262
00:10:49,020 --> 00:10:50,010
parallel documents.

263
00:10:50,010 --> 00:10:53,490
So we find a web page that the
original version might be in

264
00:10:53,490 --> 00:10:55,620
English, but then they've
localized into 10 more

265
00:10:55,620 --> 00:10:59,440
languages, and we would find all
those parallel documents.

266
00:10:59,440 --> 00:11:01,380
Other good examples of parallel
documents are the

267
00:11:01,380 --> 00:11:02,450
United Nations.

268
00:11:02,450 --> 00:11:04,500
They publish all of their
documents in their six

269
00:11:04,500 --> 00:11:05,800
official languages.

270
00:11:05,800 --> 00:11:07,870
The European Parliament
publishes all of their

271
00:11:07,870 --> 00:11:09,860
documents in 21 languages.

272
00:11:09,860 --> 00:11:11,910
And that's all really
good data for us.

273
00:11:11,910 --> 00:11:15,020
The UN data and the European
Parliament data, it's very

274
00:11:15,020 --> 00:11:18,200
high-quality data, but it's
actually a very tiny amount.

275
00:11:18,200 --> 00:11:19,860
It's like a little drop
in the bucket of the

276
00:11:19,860 --> 00:11:21,760
amount of data we need.

277
00:11:21,760 --> 00:11:23,960
The majority of our data, like
I was saying earlier, comes

278
00:11:23,960 --> 00:11:24,820
from the web, right?

279
00:11:24,820 --> 00:11:26,100
Tons of data on the web.

280
00:11:26,100 --> 00:11:29,590
The problem with the web is
that data is noisy, right?

281
00:11:29,590 --> 00:11:30,670
It is a mess.

282
00:11:30,670 --> 00:11:33,930
Anyone who's done anything on
the web with processing web

283
00:11:33,930 --> 00:11:35,720
data is like, this
stuff is crazy.

284
00:11:35,720 --> 00:11:38,170
You find all sorts of messy
junk on the web.

285
00:11:38,170 --> 00:11:40,910
But our system is able to learn,
and sort of in the same

286
00:11:40,910 --> 00:11:42,000
way, that soup thing, right?

287
00:11:42,000 --> 00:11:44,720
Imperfect things, right, we can
still learn from that data

288
00:11:44,720 --> 00:11:47,430
and learn good translations.

289
00:11:47,430 --> 00:11:51,040
So here's a diagram of how
our system works, a

290
00:11:51,040 --> 00:11:52,570
simple version of it.

291
00:11:52,570 --> 00:11:55,500
We've been talking mostly about
the translations in

292
00:11:55,500 --> 00:11:57,410
parallel corpora.

293
00:11:57,410 --> 00:12:00,170
The other part is modelling
and the model structure of

294
00:12:00,170 --> 00:12:03,530
language that we use.

295
00:12:03,530 --> 00:12:05,340
So this kind of describes
that.

296
00:12:05,340 --> 00:12:08,650
So here's a German sentence
translated to English.

297
00:12:08,650 --> 00:12:12,070
And we use a phrase-based
translation model.

298
00:12:12,070 --> 00:12:15,570
And the way we model this is by
assigning probabilities to

299
00:12:15,570 --> 00:12:17,660
certain aspects of
language, right?

300
00:12:17,660 --> 00:12:19,380
The first one is segmentation.

301
00:12:19,380 --> 00:12:23,550
We need to figure out how to
break that sentence up.

302
00:12:23,550 --> 00:12:25,810
For German, at least we know
how to break up words.

303
00:12:25,810 --> 00:12:28,420
Other languages, like
Lao, don't have

304
00:12:28,420 --> 00:12:29,490
spaces between words.

305
00:12:29,490 --> 00:12:31,230
So that becomes an even harder
problem, because you have to

306
00:12:31,230 --> 00:12:34,550
find the space where the
word boundaries are.

307
00:12:34,550 --> 00:12:36,680
At least German, we have the
word boundaries, but we still

308
00:12:36,680 --> 00:12:37,910
find phrase boundaries, right?

309
00:12:37,910 --> 00:12:42,640
We decide that "nach Kanada" is
a phrase, and we don't look

310
00:12:42,640 --> 00:12:45,796
at just "nach" and
just "Kanada."

311
00:12:45,796 --> 00:12:47,570
The second piece
is translation.

312
00:12:47,570 --> 00:12:50,850
That's the sort of obvious one,
that a phrase translates

313
00:12:50,850 --> 00:12:51,910
to another phrase, right?

314
00:12:51,910 --> 00:12:54,230
So "nach Kanada" that translates
to "in Canada." .

315
00:12:54,230 --> 00:12:56,860
So we have probabilities
for particular phrase

316
00:12:56,860 --> 00:12:57,990
translations.

317
00:12:57,990 --> 00:12:59,980
And then distortions, like
reordering, right?

318
00:12:59,980 --> 00:13:04,870
So you can see how some of these
phrases flip around.

319
00:13:04,870 --> 00:13:07,090
What our system does is we model
language in that way,

320
00:13:07,090 --> 00:13:08,980
based on these probabilities.

321
00:13:08,980 --> 00:13:11,670
This formula gives us the
probability of this English

322
00:13:11,670 --> 00:13:14,370
sentence given the
German sentence.

323
00:13:14,370 --> 00:13:17,960
And from data, we learn those
probabilities for lots of

324
00:13:17,960 --> 00:13:23,260
phrases and possible ways of
doing this translation.

325
00:13:23,260 --> 00:13:27,530
Then when you give us some new
text, we do a search process

326
00:13:27,530 --> 00:13:29,430
through all the possible phrases
we've seen, all the

327
00:13:29,430 --> 00:13:31,590
different things, to
produce the most

328
00:13:31,590 --> 00:13:34,180
probable translated text.

329
00:13:34,180 --> 00:13:35,680
Make sense?

330
00:13:35,680 --> 00:13:37,930
Cool.

331
00:13:37,930 --> 00:13:38,220
OK.

332
00:13:38,220 --> 00:13:41,790
So where are we today with
Google Translate?

333
00:13:41,790 --> 00:13:43,730
Google Translate,
translate.google.com, is our

334
00:13:43,730 --> 00:13:45,070
main property.

335
00:13:45,070 --> 00:13:48,620
We also have great mobile
apps on Android and iOS.

336
00:13:48,620 --> 00:13:51,420
And Chrome is a really
interesting case.

337
00:13:51,420 --> 00:13:52,860
A lot of you have probably
seen this.

338
00:13:52,860 --> 00:13:55,160
When you land on a Chinese
page, it'll pop a little

339
00:13:55,160 --> 00:13:56,680
banner down and say, hey,
this is Chinese.

340
00:13:56,680 --> 00:13:57,630
Do you want to translate it?

341
00:13:57,630 --> 00:13:58,090
And you're like, sure.

342
00:13:58,090 --> 00:13:59,240
And then a second later &mdash;

343
00:13:59,240 --> 00:14:00,350
less than a second later &mdash;

344
00:14:00,350 --> 00:14:02,540
you've got a translated
web page.

345
00:14:02,540 --> 00:14:05,120
We're seeing this really change
how people use the web,

346
00:14:05,120 --> 00:14:07,120
because you're no longer running
into that language

347
00:14:07,120 --> 00:14:11,160
barrier of like, oh, I wanted
to read about this temple in

348
00:14:11,160 --> 00:14:15,620
China, but all I can find is
English guidebook things.

349
00:14:15,620 --> 00:14:17,460
But really, I want to read what
the locals think about

350
00:14:17,460 --> 00:14:17,550
this thing.

351
00:14:17,550 --> 00:14:18,970
You can find some document
written in

352
00:14:18,970 --> 00:14:20,560
Chinese and read it.

353
00:14:20,560 --> 00:14:22,330
I think that's a really
incredible thing we can do

354
00:14:22,330 --> 00:14:24,210
with Chrome.

355
00:14:24,210 --> 00:14:25,790
We've got some really
cool numbers too.

356
00:14:25,790 --> 00:14:29,140
So we've got over 200 million
users of Google Translate.

357
00:14:29,140 --> 00:14:32,800
This is across our mobile apps
and our desktop apps.

358
00:14:32,800 --> 00:14:35,130
92% of those users come
from outside the

359
00:14:35,130 --> 00:14:36,020
United States, right?

360
00:14:36,020 --> 00:14:39,810
So that's a big user base, and
not even big here in the

361
00:14:39,810 --> 00:14:40,960
United States.

362
00:14:40,960 --> 00:14:43,970
We're doing a billion
translations a day, and that's

363
00:14:43,970 --> 00:14:46,730
the equivalent of the amount
of text you'd find in a

364
00:14:46,730 --> 00:14:48,300
million books.

365
00:14:48,300 --> 00:14:50,040
Every day, we're translating
that amount of text, and

366
00:14:50,040 --> 00:14:52,890
that's more text than all of
the world's professional

367
00:14:52,890 --> 00:14:55,330
translators translate
in an entire year.

368
00:14:55,330 --> 00:14:57,610
So every day, we're translating
a massive amount

369
00:14:57,610 --> 00:15:00,040
of content.

370
00:15:00,040 --> 00:15:00,115
Cool.

371
00:15:00,115 --> 00:15:02,890
So now I'm going to jump
into some demos.

372
00:15:02,890 --> 00:15:05,920
And live demos always fail,
so we'll see how they go.

373
00:15:05,920 --> 00:15:08,670

374
00:15:08,670 --> 00:15:11,710
So I'm going to start with,
here's our desktop UI.

375
00:15:11,710 --> 00:15:15,740
Hopefully, a lot of you are
familiar with that.

376
00:15:15,740 --> 00:15:19,620
And I can type in to transition
"Google I/O 2013 is

377
00:15:19,620 --> 00:15:23,040
the best." And then here,
you can see the Chinese

378
00:15:23,040 --> 00:15:24,290
translation.

379
00:15:24,290 --> 00:15:25,770
We can hover over these
phrases and

380
00:15:25,770 --> 00:15:27,490
see how they align.

381
00:15:27,490 --> 00:15:28,300
You can make edits.

382
00:15:28,300 --> 00:15:29,820
You can click on this.

383
00:15:29,820 --> 00:15:32,580
And the numerical date is fine,
but I'm going to change

384
00:15:32,580 --> 00:15:35,280
it to the Chinese characters
here, because that helps me

385
00:15:35,280 --> 00:15:38,250
learn the pronunciation
of those characters.

386
00:15:38,250 --> 00:15:40,380
And then a newer feature we
launched just about a month

387
00:15:40,380 --> 00:15:42,590
ago, it's called Phrasebooks.

388
00:15:42,590 --> 00:15:44,240
This lets you save
translations that

389
00:15:44,240 --> 00:15:45,070
are useful to you.

390
00:15:45,070 --> 00:15:47,670
You can see that I'm vegetarian,
and so when I'm

391
00:15:47,670 --> 00:15:50,560
traveling, I try to make sure I
have some phrases with me of

392
00:15:50,560 --> 00:15:52,220
how to tell people in different
languages that I

393
00:15:52,220 --> 00:15:53,010
don't eat meat.

394
00:15:53,010 --> 00:15:55,050
So I've been saving
a bunch of those.

395
00:15:55,050 --> 00:15:58,200
I'll save this one I just put
in here, which gives me the

396
00:15:58,200 --> 00:16:02,290
chance to show you something
we launched in mobile just

397
00:16:02,290 --> 00:16:04,290
last week, I think.

398
00:16:04,290 --> 00:16:05,940
Let's see if can
switch to my &mdash;

399
00:16:05,940 --> 00:16:07,645
oh, that's my son.

400
00:16:07,645 --> 00:16:09,197
All right, I'm going to
switch away, so you

401
00:16:09,197 --> 00:16:10,447
don't see my password.

402
00:16:10,447 --> 00:16:13,649

403
00:16:13,649 --> 00:16:14,630
OK, we're back.

404
00:16:14,630 --> 00:16:18,120
So here's our translate app on
Android, and I've already

405
00:16:18,120 --> 00:16:19,100
switched to the Phrasebook
view.

406
00:16:19,100 --> 00:16:20,940
You can see those
same phrases.

407
00:16:20,940 --> 00:16:23,240
And I can sync, and hopefully
we'll see &mdash; yup, there's that

408
00:16:23,240 --> 00:16:26,480
new phrase that I just put
in on the desktop.

409
00:16:26,480 --> 00:16:28,790
In the Phrasebook, you can open
that up, and then we can

410
00:16:28,790 --> 00:16:29,420
listen to that.

411
00:16:29,420 --> 00:16:33,300
So I want to say this to my
friend I just met at I/O that

412
00:16:33,300 --> 00:16:33,930
speaks Chinese.

413
00:16:33,930 --> 00:16:38,840
[COMPUTER SPEAKING CHINESE]

414
00:16:38,840 --> 00:16:39,860
JOSH ESTELLE: Pretty good?

415
00:16:39,860 --> 00:16:40,790
How's my Chinese?

416
00:16:40,790 --> 00:16:42,255
We got any Chinese speakers?

417
00:16:42,255 --> 00:16:42,510
Pretty good?

418
00:16:42,510 --> 00:16:44,440
Yeah, all right.

419
00:16:44,440 --> 00:16:44,960
Cool.

420
00:16:44,960 --> 00:16:47,210
You can also use this supersize
mode, right?

421
00:16:47,210 --> 00:16:49,440
So if I need to reach someone
way in the back of the room,

422
00:16:49,440 --> 00:16:51,060
they can read that.

423
00:16:51,060 --> 00:16:53,270
Or this is great for showing a
cab driver where you need to

424
00:16:53,270 --> 00:16:54,060
go, that sort of thing.

425
00:16:54,060 --> 00:16:55,180
You don't have to hand
them your phone.

426
00:16:55,180 --> 00:16:58,140
You're just kind of like,
look at this.

427
00:16:58,140 --> 00:16:59,390
So that's that.

428
00:16:59,390 --> 00:17:02,630

429
00:17:02,630 --> 00:17:05,560
Some of the other things I'm
really excited about in our

430
00:17:05,560 --> 00:17:07,550
mobile app is some of the
ways we're dealing

431
00:17:07,550 --> 00:17:09,160
with inputting text.

432
00:17:09,160 --> 00:17:11,810
So when you're traveling, it's
not always so easy to get text

433
00:17:11,810 --> 00:17:13,079
into your app.

434
00:17:13,079 --> 00:17:16,056
The first one is handwriting
input.

435
00:17:16,056 --> 00:17:18,359
Us Americans, right, we're used
to keyboards like this.

436
00:17:18,359 --> 00:17:20,089
But there's a lot of people in
the developing world that are

437
00:17:20,089 --> 00:17:23,010
coming to mobile phones as their
first computing device,

438
00:17:23,010 --> 00:17:27,869
and they're maybe not used to
ASCII keyboards, right?

439
00:17:27,869 --> 00:17:29,730
They might be used to just
drawing Chinese characters.

440
00:17:29,730 --> 00:17:31,440
That's how they've
always written.

441
00:17:31,440 --> 00:17:33,570
So this handwriting is really
great for that.

442
00:17:33,570 --> 00:17:36,390
I don't know that much Chinese,
but I know one.

443
00:17:36,390 --> 00:17:37,370
I didn't quite get it right.

444
00:17:37,370 --> 00:17:40,715
I know one kind of interesting
character.

445
00:17:40,715 --> 00:17:41,835
Did I get it?

446
00:17:41,835 --> 00:17:42,190
Come on.

447
00:17:42,190 --> 00:17:44,955
Ah, shoot.

448
00:17:44,955 --> 00:17:47,690
I'm going to try it
one more tine.

449
00:17:47,690 --> 00:17:49,680
I assure you, this is not
our system's fault.

450
00:17:49,680 --> 00:17:53,480
This is my terrible
Chinese fault.

451
00:17:53,480 --> 00:17:55,125
Can I get "fire"?

452
00:17:55,125 --> 00:17:56,440
Yeah, fire.

453
00:17:56,440 --> 00:17:56,540
ROHIT KHARE: Fire.

454
00:17:56,540 --> 00:17:56,680
JOSH ESTELLE: Wait, no.

455
00:17:56,680 --> 00:17:57,230
There's not a fire.

456
00:17:57,230 --> 00:17:59,670
Don't worry.

457
00:17:59,670 --> 00:18:00,890
Cool, so that's handwriting.

458
00:18:00,890 --> 00:18:02,440
The next one is camera input.

459
00:18:02,440 --> 00:18:06,810
So let's imagine we're
in a zoo in Tokyo.

460
00:18:06,810 --> 00:18:07,550
Rohit's going to help me out.

461
00:18:07,550 --> 00:18:09,550
He's going to be my zoo sign.

462
00:18:09,550 --> 00:18:10,230
What does this say?

463
00:18:10,230 --> 00:18:11,280
I have no idea.

464
00:18:11,280 --> 00:18:12,430
Well, I'm in Tokyo, so I better

465
00:18:12,430 --> 00:18:15,580
change this to Japanese.

466
00:18:15,580 --> 00:18:18,393
I'll just take a picture
of that, get

467
00:18:18,393 --> 00:18:22,290
that lined up in there.

468
00:18:22,290 --> 00:18:25,320
And so this will recognize the
text, and then I can just

469
00:18:25,320 --> 00:18:28,830
swipe my finger over the text
I want to understand.

470
00:18:28,830 --> 00:18:29,650
And now, oh, there we go.

471
00:18:29,650 --> 00:18:32,650
The amphibious reptile house
must be over there somewhere.

472
00:18:32,650 --> 00:18:34,970
Watch out for amphibians
if you're sitting in

473
00:18:34,970 --> 00:18:37,330
that side of the room.

474
00:18:37,330 --> 00:18:37,840
Cool.

475
00:18:37,840 --> 00:18:39,830
And then also if you, need to
talk to someone, we have

476
00:18:39,830 --> 00:18:43,206
conversation mode, which
will handle your voice.

477
00:18:43,206 --> 00:18:45,890
Since we're in conversation
mode, I can just be like,

478
00:18:45,890 --> 00:18:50,350
"Hey, do you know where the
amphibious reptile house is?"

479
00:18:50,350 --> 00:18:57,180
[COMPUTER SPEAKING JAPANESE]

480
00:18:57,180 --> 00:18:57,660
JOSH ESTELLE: All right.

481
00:18:57,660 --> 00:18:59,780
Of course, I just read the sign,
so I'm not sure why I

482
00:18:59,780 --> 00:19:01,340
needed to ask that.

483
00:19:01,340 --> 00:19:02,725
I was just double checking.

484
00:19:02,725 --> 00:19:04,660
So that's conversation mode.

485
00:19:04,660 --> 00:19:07,010
And then the last thing, I'm
really excited about &mdash; we

486
00:19:07,010 --> 00:19:09,850
launched pretty recently &mdash;

487
00:19:09,850 --> 00:19:13,120
is what if you're at a
conference and the wireless is

488
00:19:13,120 --> 00:19:15,480
really terrible, and you just
can't seem to get the

489
00:19:15,480 --> 00:19:17,720
translations you need?

490
00:19:17,720 --> 00:19:21,630
I'm going to simulate that by
going into airplane mode.

491
00:19:21,630 --> 00:19:23,410
Now I'm just going
to type here.

492
00:19:23,410 --> 00:19:28,075
"Hello." Oh, and I still
have a translation.

493
00:19:28,075 --> 00:19:33,620

494
00:19:33,620 --> 00:19:37,520
"How are you?" So this
translation is all happening

495
00:19:37,520 --> 00:19:41,020
offline, on my device, no
network connection.

496
00:19:41,020 --> 00:19:42,000
Pretty cool, huh?

497
00:19:42,000 --> 00:19:43,970
So this is a great when
you're traveling.

498
00:19:43,970 --> 00:19:45,130
You've got expensive data.

499
00:19:45,130 --> 00:19:48,280
You've got maybe no data at
all, but you can still do

500
00:19:48,280 --> 00:19:49,130
translation.

501
00:19:49,130 --> 00:19:53,330
Now this does require you to
download some language packs.

502
00:19:53,330 --> 00:19:56,530
So each language is about
100 megabytes of data.

503
00:19:56,530 --> 00:19:58,680
But once you have it, you can do
offline translations, which

504
00:19:58,680 --> 00:20:01,350
we're really excited about.

505
00:20:01,350 --> 00:20:02,290
Cool.

506
00:20:02,290 --> 00:20:05,000
So let me just talk
a little bit more

507
00:20:05,000 --> 00:20:06,550
about where we're going.

508
00:20:06,550 --> 00:20:08,730
What's next for Google
Translate?

509
00:20:08,730 --> 00:20:09,560
More languages.

510
00:20:09,560 --> 00:20:10,820
We're up to 71.

511
00:20:10,820 --> 00:20:12,570
That's a great number, but
there are thousands of

512
00:20:12,570 --> 00:20:15,180
languages in the world, and we
want to keep adding more.

513
00:20:15,180 --> 00:20:18,370
So I'm sure someone after this
talk is going to come ask me,

514
00:20:18,370 --> 00:20:20,350
what about my language?

515
00:20:20,350 --> 00:20:24,050
We get that all the time, and I
promise we're working on it.

516
00:20:24,050 --> 00:20:27,140
It always becomes a matter of if
we can get enough data for

517
00:20:27,140 --> 00:20:28,040
a particular language.

518
00:20:28,040 --> 00:20:30,160
So usually the best thing
people can do is get

519
00:20:30,160 --> 00:20:33,500
translated content out on the
web where it can be crawled.

520
00:20:33,500 --> 00:20:35,570
And we'll find it, and we'll
learn from it, and it'll help

521
00:20:35,570 --> 00:20:36,880
our system.

522
00:20:36,880 --> 00:20:38,990
We want better quality,
of course.

523
00:20:38,990 --> 00:20:40,160
We're really proud
of our quality.

524
00:20:40,160 --> 00:20:42,090
We think our translations
are really usable.

525
00:20:42,090 --> 00:20:43,650
They can help you understand
a document.

526
00:20:43,650 --> 00:20:45,110
They can help you communicate.

527
00:20:45,110 --> 00:20:45,970
They're not perfect though.

528
00:20:45,970 --> 00:20:49,070
You don't necessarily want to
localize your website just

529
00:20:49,070 --> 00:20:51,150
straight up and trust the
machine translation without

530
00:20:51,150 --> 00:20:52,120
anyone reviewing it, right?

531
00:20:52,120 --> 00:20:53,060
You want to be careful.

532
00:20:53,060 --> 00:20:53,830
But we want to get there.

533
00:20:53,830 --> 00:20:56,500
We want our translations to
get better and better.

534
00:20:56,500 --> 00:20:58,170
We also want translation
to be ubiquitous.

535
00:20:58,170 --> 00:21:00,800
No matter where you are, you
should have access to a

536
00:21:00,800 --> 00:21:01,990
translation.

537
00:21:01,990 --> 00:21:04,466
So if you're browsing a website
in Chrome, boom, you

538
00:21:04,466 --> 00:21:05,370
get it translated.

539
00:21:05,370 --> 00:21:07,510
You run into a sign, you pull
out your phone, you get it

540
00:21:07,510 --> 00:21:08,330
translated.

541
00:21:08,330 --> 00:21:10,250
There are still places that
are hard for people to get

542
00:21:10,250 --> 00:21:10,890
translations.

543
00:21:10,890 --> 00:21:12,930
We want to make sure any time
you encounter text that you

544
00:21:12,930 --> 00:21:14,860
can get it.

545
00:21:14,860 --> 00:21:16,340
And we want real-time
communication.

546
00:21:16,340 --> 00:21:19,970
So we want you to be able to
translate things instantly,

547
00:21:19,970 --> 00:21:21,750
quickly, right when
you need it.

548
00:21:21,750 --> 00:21:25,080
We want those conversations to
happen, spoken, real-time

549
00:21:25,080 --> 00:21:27,860
conversations in other
languages too.

550
00:21:27,860 --> 00:21:29,501
So with that, I'll turn it over
to Rohit, and he's going

551
00:21:29,501 --> 00:21:32,090
to tell you more
about the API.

552
00:21:32,090 --> 00:21:32,270
ROHIT KHARE: Yeah.

553
00:21:32,270 --> 00:21:33,750
Thank you, Josh.

554
00:21:33,750 --> 00:21:35,870
Glad for the introduction to
the science behind Google

555
00:21:35,870 --> 00:21:38,450
Translate, and I think I want
to talk to you about what we

556
00:21:38,450 --> 00:21:42,320
do with it and what you
can do with it.

557
00:21:42,320 --> 00:21:43,720
What's important to realize that
we think translation's

558
00:21:43,720 --> 00:21:44,620
important in context.

559
00:21:44,620 --> 00:21:47,440
So if I receive a Gmail that's
happens to be in Japanese,

560
00:21:47,440 --> 00:21:49,430
notice that we have that link
right there to convert that

561
00:21:49,430 --> 00:21:50,610
back to English.

562
00:21:50,610 --> 00:21:53,220
Now, we use this in our consumer
applications, like

563
00:21:53,220 --> 00:21:54,460
Docs and Spreadsheets.

564
00:21:54,460 --> 00:21:57,550
We use it in our internal
applications, like approving

565
00:21:57,550 --> 00:22:01,420
advertising, and understanding
how Search queries should be

566
00:22:01,420 --> 00:22:03,910
indexed and shared
across languages.

567
00:22:03,910 --> 00:22:06,320
But we use our own
dog food here.

568
00:22:06,320 --> 00:22:08,600
We use and API, and we make them
over with third parties.

569
00:22:08,600 --> 00:22:11,790
So this is a screenshot from a
partner called The Backplane.

570
00:22:11,790 --> 00:22:16,730
They are a social site that
started out with Lady Gaga's

571
00:22:16,730 --> 00:22:18,830
management company and are now
working with other brands like

572
00:22:18,830 --> 00:22:20,170
Nike and Coke and so on.

573
00:22:20,170 --> 00:22:22,610
And they create communities
for fans.

574
00:22:22,610 --> 00:22:25,090
And unlike, say, a friendship
community of people you met at

575
00:22:25,090 --> 00:22:27,910
college, who will probably all
speak the same language, the

576
00:22:27,910 --> 00:22:31,350
superfans around the world
really are passionate and love

577
00:22:31,350 --> 00:22:32,510
to connect, but they
don't always

578
00:22:32,510 --> 00:22:33,960
speak the same language.

579
00:22:33,960 --> 00:22:36,050
So here in this chat, we can
see that an English speaker

580
00:22:36,050 --> 00:22:38,290
and an Italian speaker
are able to go

581
00:22:38,290 --> 00:22:39,610
fluidly back and forth.

582
00:22:39,610 --> 00:22:41,870
And they're using the same
API technology as

583
00:22:41,870 --> 00:22:44,420
we do here at Google.

584
00:22:44,420 --> 00:22:46,810
So the important thing I want to
say up front is that a lot

585
00:22:46,810 --> 00:22:50,670
of the translate technology we
just saw is very advanced, and

586
00:22:50,670 --> 00:22:52,440
there's some very amazing things
you can do by combining

587
00:22:52,440 --> 00:22:55,440
speech and handwriting and
image recognition.

588
00:22:55,440 --> 00:22:57,200
But I want to say that the core
technology is very much

589
00:22:57,200 --> 00:22:58,210
open for business.

590
00:22:58,210 --> 00:23:00,670
It's part of the Google Cloud
Platform, and you've heard a

591
00:23:00,670 --> 00:23:02,790
lot about that this week at
Google I/O. We have basic

592
00:23:02,790 --> 00:23:05,330
services in compute, like App
Engine and Compute Engine,

593
00:23:05,330 --> 00:23:08,060
storage services, but also a
great way to take advantage of

594
00:23:08,060 --> 00:23:12,350
the best of that Google has to
offer, from apps to Maps to

595
00:23:12,350 --> 00:23:14,900
APIs for data processing and
advertising analytics, and

596
00:23:14,900 --> 00:23:16,390
including Translate.

597
00:23:16,390 --> 00:23:19,350
Translate's been around
since late 2011.

598
00:23:19,350 --> 00:23:21,580
It's one of our larger and more
successful businesses

599
00:23:21,580 --> 00:23:22,600
within the cloud.

600
00:23:22,600 --> 00:23:25,790
Over 3 million developers use
the Cloud Platform projects,

601
00:23:25,790 --> 00:23:27,760
and 300,000 folks come
and work on the

602
00:23:27,760 --> 00:23:28,720
platform every month.

603
00:23:28,720 --> 00:23:30,720
And we'd like keep growing that,
and this is a key part

604
00:23:30,720 --> 00:23:32,152
of that strategy.

605
00:23:32,152 --> 00:23:35,450
And it's $20 per million
characters translated.

606
00:23:35,450 --> 00:23:37,090
And it's not always easy to get
your head around that, but

607
00:23:37,090 --> 00:23:40,470
$1 for localization can often
get just a word or two.

608
00:23:40,470 --> 00:23:42,690
But in machine translation, that
can be over 100 pages of

609
00:23:42,690 --> 00:23:43,950
English content.

610
00:23:43,950 --> 00:23:46,560
It's often the case people say,
well, is $20 per million

611
00:23:46,560 --> 00:23:47,960
characters expensive or not?

612
00:23:47,960 --> 00:23:49,740
And it's actually quite
reasonable.

613
00:23:49,740 --> 00:23:51,990
It's best to get out there and
start experimenting, and you

614
00:23:51,990 --> 00:23:53,670
can scale up.

615
00:23:53,670 --> 00:23:56,240
Until you even have
Wikipedia-style content, you

616
00:23:56,240 --> 00:23:59,370
will still not be taking that
much that goes out of your

617
00:23:59,370 --> 00:24:01,640
data quota limits.

618
00:24:01,640 --> 00:24:02,500
So how do you call it?

619
00:24:02,500 --> 00:24:03,490
Real briefly mechanics.

620
00:24:03,490 --> 00:24:04,560
It's really quite simple.

621
00:24:04,560 --> 00:24:06,590
As said, there's Core
2 core services.

622
00:24:06,590 --> 00:24:10,080
In this case, we're doing a
GET request with your API

623
00:24:10,080 --> 00:24:11,080
console key.

624
00:24:11,080 --> 00:24:13,370
Here's "hello world." I want
the target in German.

625
00:24:13,370 --> 00:24:15,910
We're automatically detecting
the source language and giving

626
00:24:15,910 --> 00:24:18,340
you the output, "hallo welt,"
and telling you that we

627
00:24:18,340 --> 00:24:20,620
thought it was English source.

628
00:24:20,620 --> 00:24:23,050
We also do great things with
automatic HTML parsing.

629
00:24:23,050 --> 00:24:25,040
We're often doing an input
that's coming in from the web.

630
00:24:25,040 --> 00:24:27,520
And in this case, this is that
phrase about going to the

631
00:24:27,520 --> 00:24:28,110
conference.

632
00:24:28,110 --> 00:24:30,280
And the conference, you'll here
notice is capital K in

633
00:24:30,280 --> 00:24:33,750
German, and the word "fly" is
in bold, in bold markup.

634
00:24:33,750 --> 00:24:35,780
And here's the output where
"fly" is in bold, but notice

635
00:24:35,780 --> 00:24:37,340
it's much earlier
in the sentence.

636
00:24:37,340 --> 00:24:39,310
The C in conference has
been lowercased.

637
00:24:39,310 --> 00:24:41,090
So it's always great for
realizing that you can use

638
00:24:41,090 --> 00:24:43,050
HTML markup, and the
markup will float

639
00:24:43,050 --> 00:24:44,190
with the correct phrase.

640
00:24:44,190 --> 00:24:45,590
So this again makes it a little
easier to integrate in

641
00:24:45,590 --> 00:24:46,645
your websites.

642
00:24:46,645 --> 00:24:49,040
And it's available also in
products like Google Apps

643
00:24:49,040 --> 00:24:51,320
Script, if you're working for
lightweight prototyping in our

644
00:24:51,320 --> 00:24:53,256
Spreadsheets or Docs.

645
00:24:53,256 --> 00:24:55,610
Here's the same phrase
in Spanish.

646
00:24:55,610 --> 00:24:56,920
So the important thing you need
to realize is that we're

647
00:24:56,920 --> 00:24:59,000
taking the two most important
core things about our

648
00:24:59,000 --> 00:25:01,140
Statistical Machine Translation
engine, which is

649
00:25:01,140 --> 00:25:03,110
language detection, which is
that you know what your

650
00:25:03,110 --> 00:25:06,000
input's coming in as, and
language translation between

651
00:25:06,000 --> 00:25:07,560
our supported languages.

652
00:25:07,560 --> 00:25:08,610
Sometimes we do a release.

653
00:25:08,610 --> 00:25:10,330
Our most recent languages
will be in Alpha.

654
00:25:10,330 --> 00:25:11,550
We're working on our data.

655
00:25:11,550 --> 00:25:13,600
Some of them are not yet
supported in the API, but by

656
00:25:13,600 --> 00:25:15,855
and large, as they graduate,
they are always available to

657
00:25:15,855 --> 00:25:18,050
you through the API.

658
00:25:18,050 --> 00:25:20,600
Now, of course, we have a lot
of products where we make it

659
00:25:20,600 --> 00:25:21,610
free to our consumers.

660
00:25:21,610 --> 00:25:24,770
For commercial use, for you as
third-party developers, we

661
00:25:24,770 --> 00:25:25,810
definitely want to
encourage that.

662
00:25:25,810 --> 00:25:28,020
But we have kind of two
key rules of the road.

663
00:25:28,020 --> 00:25:29,500
One is attribution.

664
00:25:29,500 --> 00:25:31,810
It's really important that
humans know that this is

665
00:25:31,810 --> 00:25:33,695
machine-translated output
in case there

666
00:25:33,695 --> 00:25:35,280
are errors or omissions.

667
00:25:35,280 --> 00:25:38,120
It's really important to us that
humans know that it's our

668
00:25:38,120 --> 00:25:40,030
machine-translation output,
and if you want to use the

669
00:25:40,030 --> 00:25:42,440
Google logo, there are some
additional rules and

670
00:25:42,440 --> 00:25:44,470
suggestions about
how to do that.

671
00:25:44,470 --> 00:25:47,100
But it's also important that
machines know that it's

672
00:25:47,100 --> 00:25:48,880
machine-translation output.

673
00:25:48,880 --> 00:25:51,670
As he mentioned, the way machine
translation works is

674
00:25:51,670 --> 00:25:54,100
by building upon all the work
in the parallel corpora, the

675
00:25:54,100 --> 00:25:56,670
parallel text that are out
there that humans create.

676
00:25:56,670 --> 00:25:59,080
And the last thing we want to
see is taking content from our

677
00:25:59,080 --> 00:26:02,090
API and republishing it back on
the web in a way that makes

678
00:26:02,090 --> 00:26:03,260
other research groups and

679
00:26:03,260 --> 00:26:07,580
developers' input less reliable.

680
00:26:07,580 --> 00:26:10,130
So with that, the rules of the
road on how it works and how

681
00:26:10,130 --> 00:26:13,730
to call it, I want to talk about
when it gets used, and

682
00:26:13,730 --> 00:26:16,340
talk about two broad cases I
looked at when we saw our

683
00:26:16,340 --> 00:26:19,030
traces of who was using
our API and for what.

684
00:26:19,030 --> 00:26:21,160
Now, some developers are
offline, are some developers

685
00:26:21,160 --> 00:26:21,840
are on the web.

686
00:26:21,840 --> 00:26:23,740
So in looking at our logs, I
found a couple of clusters of

687
00:26:23,740 --> 00:26:24,940
people who I thought
were offline.

688
00:26:24,940 --> 00:26:27,660
And one huge area of growth is
mobile applications, and

689
00:26:27,660 --> 00:26:30,250
you're delivering the experience
on Android or iOS

690
00:26:30,250 --> 00:26:31,380
or BlackBerry.

691
00:26:31,380 --> 00:26:34,120
You could simply make an
internet call, a REST call,

692
00:26:34,120 --> 00:26:37,120
and display that online on
the tablet, on the phone.

693
00:26:37,120 --> 00:26:39,150
We've see business process
applications.

694
00:26:39,150 --> 00:26:41,780
For example, at Google we use
all of our bug reports that

695
00:26:41,780 --> 00:26:42,930
come in from the field.

696
00:26:42,930 --> 00:26:45,620
We have clustering algorithms
and train people who look at

697
00:26:45,620 --> 00:26:48,020
the field reports, but we have
to bring them back into a

698
00:26:48,020 --> 00:26:50,130
common language, say
English, to do so.

699
00:26:50,130 --> 00:26:52,720
So these are back office
processes.

700
00:26:52,720 --> 00:26:56,120
There are media monitoring
applications, where you want

701
00:26:56,120 --> 00:26:58,640
to know how your brand or
company is being perceived

702
00:26:58,640 --> 00:26:59,390
around the world.

703
00:26:59,390 --> 00:27:01,950
And so rather than just
translate the name of your

704
00:27:01,950 --> 00:27:04,300
products and see how many times
it gets mentioned in the

705
00:27:04,300 --> 00:27:07,220
media, why not bring all that
media in, translate those

706
00:27:07,220 --> 00:27:09,650
entire articles, and be able to
look at the sentiment and

707
00:27:09,650 --> 00:27:14,680
look at the themes and the
content around the world.

708
00:27:14,680 --> 00:27:17,430
And another subclass was around

709
00:27:17,430 --> 00:27:18,880
hybrid translation companies.

710
00:27:18,880 --> 00:27:20,690
So you take machine-translation
output,

711
00:27:20,690 --> 00:27:23,560
and you might have expertise in
medical or real estate or

712
00:27:23,560 --> 00:27:25,530
in a certain country,
and you have a staff

713
00:27:25,530 --> 00:27:26,690
that makes that better.

714
00:27:26,690 --> 00:27:29,750
So there are companies that
have used our API to help

715
00:27:29,750 --> 00:27:31,750
bootstrap the translation
process.

716
00:27:31,750 --> 00:27:33,980
But most visibly, you've
probably seen Google Translate

717
00:27:33,980 --> 00:27:34,790
on the web.

718
00:27:34,790 --> 00:27:36,600
And an obvious place
is e-commerce.

719
00:27:36,600 --> 00:27:38,250
If you can put it in
a box and FedEx it,

720
00:27:38,250 --> 00:27:39,320
you can be an exporter.

721
00:27:39,320 --> 00:27:40,690
But you can't export
much unless your

722
00:27:40,690 --> 00:27:41,710
customers can find you.

723
00:27:41,710 --> 00:27:44,130
And so we want to do our best
to make sure that you can

724
00:27:44,130 --> 00:27:46,580
create your product listings,
your product reviews, get them

725
00:27:46,580 --> 00:27:50,050
indexed, get them visible, and
attract new customers.

726
00:27:50,050 --> 00:27:52,060
But I was also surprised to find
out the largest customer

727
00:27:52,060 --> 00:27:54,030
within e-commerce turned out to
be stuff you can't put in a

728
00:27:54,030 --> 00:27:54,880
box and export.

729
00:27:54,880 --> 00:27:58,500
It was hotels and hostels
and vacation rentals.

730
00:27:58,500 --> 00:27:59,330
And it wasn't the product

731
00:27:59,330 --> 00:28:01,290
descriptions, it was the reviews.

732
00:28:01,290 --> 00:28:03,450
It's what people said when
they came from abroad,

733
00:28:03,450 --> 00:28:06,990
reviewed a place, and allowed
other travelers who maybe also

734
00:28:06,990 --> 00:28:09,260
didn't speak that language to
know what they thought of it.

735
00:28:09,260 --> 00:28:11,210
And this theme was really
enlightening to me.

736
00:28:11,210 --> 00:28:12,735
And we'll come back to some of
the lessons I learned from

737
00:28:12,735 --> 00:28:13,100
that later.

738
00:28:13,100 --> 00:28:15,960
But that's a case where, even
if you think you're a local

739
00:28:15,960 --> 00:28:18,530
merchant running B&B in
Monterrey, you should probably

740
00:28:18,530 --> 00:28:19,770
still consider translation.

741
00:28:19,770 --> 00:28:22,760
I can have an impact
on your business.

742
00:28:22,760 --> 00:28:23,940
Multimedia content.

743
00:28:23,940 --> 00:28:26,140
There's a lot of content on the
web today that's video,

744
00:28:26,140 --> 00:28:28,730
that's images, that's
photographs and newswire

745
00:28:28,730 --> 00:28:31,800
photos or product imagery that's
perfectly usable in

746
00:28:31,800 --> 00:28:32,760
multiple languages.

747
00:28:32,760 --> 00:28:33,770
You don't need to
read to use it.

748
00:28:33,770 --> 00:28:37,610
But you can't find it unless
that metadata, caption,

749
00:28:37,610 --> 00:28:39,657
program guide, and so
on is available to

750
00:28:39,657 --> 00:28:42,360
people in those languages.

751
00:28:42,360 --> 00:28:43,450
Language learning.

752
00:28:43,450 --> 00:28:45,430
This was a smaller sector, but
it was interesting that even

753
00:28:45,430 --> 00:28:47,690
machine translation, which can
be approximate at times, can

754
00:28:47,690 --> 00:28:50,230
be very useful in an interactive
setting where you

755
00:28:50,230 --> 00:28:52,360
are in a game or you're in
a community classroom or

756
00:28:52,360 --> 00:28:54,150
somewhere where a TA
can help you out.

757
00:28:54,150 --> 00:28:56,590
So places where you have an
interactive application can be

758
00:28:56,590 --> 00:28:59,210
also a really good
fit for our API.

759
00:28:59,210 --> 00:29:00,830
And finally, social
communities.

760
00:29:00,830 --> 00:29:02,080
And it was important to think
that it wasn't just

761
00:29:02,080 --> 00:29:05,050
communication applications,
like SMSes or places where

762
00:29:05,050 --> 00:29:07,370
people are communicating across
borders, but places

763
00:29:07,370 --> 00:29:09,570
where you can find shared
passions and communities &mdash;

764
00:29:09,570 --> 00:29:13,680
forum sites, rare diseases,
passionate collectors of

765
00:29:13,680 --> 00:29:14,680
various items.

766
00:29:14,680 --> 00:29:16,390
These are cases where your
community might be better

767
00:29:16,390 --> 00:29:18,750
served by pulling it all in one
place than having separate

768
00:29:18,750 --> 00:29:22,700
language communities and
separate language sites.

769
00:29:22,700 --> 00:29:25,366
So from these bunch of examples
of companies that are

770
00:29:25,366 --> 00:29:26,220
using it on the web,
let's talk about a

771
00:29:26,220 --> 00:29:27,210
couple of key themes.

772
00:29:27,210 --> 00:29:29,590
One is think about machine
translation when you need to

773
00:29:29,590 --> 00:29:31,000
get the gist of things.

774
00:29:31,000 --> 00:29:35,000
Human translation is great, but
the sheer cost and scale

775
00:29:35,000 --> 00:29:36,420
says that we're not going to
be able to organize the

776
00:29:36,420 --> 00:29:38,690
world's information unless we
use machine translation.

777
00:29:38,690 --> 00:29:40,750
But it's important to know its
strengths and weaknesses.

778
00:29:40,750 --> 00:29:42,810
And the thing was, when you're
looking at reviews, like a

779
00:29:42,810 --> 00:29:45,130
hotel review, I didn't need
to worry about whether the

780
00:29:45,130 --> 00:29:47,620
grammar was perfect in the
way that you expect of a

781
00:29:47,620 --> 00:29:49,630
well-written YouTube comment.

782
00:29:49,630 --> 00:29:51,870
Comments and reviews are really
great content, even if

783
00:29:51,870 --> 00:29:54,700
you can only get the
sense of it.

784
00:29:54,700 --> 00:29:57,170
You have to think about reach,
which is, are you building a

785
00:29:57,170 --> 00:29:59,490
site or an app where your
audience is going to be

786
00:29:59,490 --> 00:30:01,320
reaching you in multiple
languages and multiple

787
00:30:01,320 --> 00:30:02,230
communities?

788
00:30:02,230 --> 00:30:04,180
And that's often earlier
than you think.

789
00:30:04,180 --> 00:30:06,840
You might assume that your
audience is only shipping to

790
00:30:06,840 --> 00:30:09,660
one country in Europe, say in
France, but that doesn't mean

791
00:30:09,660 --> 00:30:10,940
that you only need to
communicate in French.

792
00:30:10,940 --> 00:30:12,310
You also have French
consumers who

793
00:30:12,310 --> 00:30:15,390
speak all the EU languages.

794
00:30:15,390 --> 00:30:16,170
And bulk.

795
00:30:16,170 --> 00:30:17,910
Think about machine translation
when there are

796
00:30:17,910 --> 00:30:20,900
applications that no one ever
thought of doing with human

797
00:30:20,900 --> 00:30:22,710
translation because it
was so obviously

798
00:30:22,710 --> 00:30:24,690
prohibitive to do so in cost.

799
00:30:24,690 --> 00:30:27,220
But if you can look at media
monitoring or look at your old

800
00:30:27,220 --> 00:30:31,690
customer reports or look at a
large amount of text, and work

801
00:30:31,690 --> 00:30:33,690
with all of your reviews rather
than just a few that

802
00:30:33,690 --> 00:30:36,420
seem to be for the top hotels.

803
00:30:36,420 --> 00:30:39,080
And finally, look for cases
where the user is in control.

804
00:30:39,080 --> 00:30:41,940
Machine translation is great if
the user has initiated or

805
00:30:41,940 --> 00:30:44,270
requested the translation
process, or is aware that I'm

806
00:30:44,270 --> 00:30:47,110
flipping between the original
Turkish and the English.

807
00:30:47,110 --> 00:30:49,100
Or if the user is the one who's
creating the content in

808
00:30:49,100 --> 00:30:50,810
the first place, and they have
the chance or the opportunity

809
00:30:50,810 --> 00:30:53,400
to know that, by telling us
that you're OK with this

810
00:30:53,400 --> 00:30:56,390
language, that your review will
now be read by people

811
00:30:56,390 --> 00:31:00,350
visiting this pizza place
from all over the world.

812
00:31:00,350 --> 00:31:02,220
So with this, I'd like to bring
it back together and say

813
00:31:02,220 --> 00:31:04,440
these are part of the whole
suite of tools at Google and

814
00:31:04,440 --> 00:31:06,730
at other places in the world
to help you go global with

815
00:31:06,730 --> 00:31:08,290
your site or your app.

816
00:31:08,290 --> 00:31:09,200
There are new markets.

817
00:31:09,200 --> 00:31:11,020
There are no more monolingual
markets.

818
00:31:11,020 --> 00:31:14,230
Even in the United States,
Hispanic consumers control

819
00:31:14,230 --> 00:31:17,540
over a trillion dollars
in household spending.

820
00:31:17,540 --> 00:31:20,290
There is a reason for growth,
because you have to be able to

821
00:31:20,290 --> 00:31:22,680
take in input and feedback
that you're getting and

822
00:31:22,680 --> 00:31:24,630
understand what your customers
are telling you and how you

823
00:31:24,630 --> 00:31:26,220
can expand.

824
00:31:26,220 --> 00:31:27,890
There are opportunities to
make sure that you are in

825
00:31:27,890 --> 00:31:28,730
compliance.

826
00:31:28,730 --> 00:31:30,820
There are a variety of
rules and cultural

827
00:31:30,820 --> 00:31:31,700
norms around the world.

828
00:31:31,700 --> 00:31:33,430
And even if you're not yet
operating in that language, at

829
00:31:33,430 --> 00:31:35,730
least knowing what your users
are saying in those languages,

830
00:31:35,730 --> 00:31:37,610
so you can review that and
be sure that that's in

831
00:31:37,610 --> 00:31:38,860
compliance.

832
00:31:38,860 --> 00:31:40,010
And to help create
connections.

833
00:31:40,010 --> 00:31:42,530
Because I think the next wave
of global growth isn't by

834
00:31:42,530 --> 00:31:44,440
franchising your business and
saying, I'm going to create a

835
00:31:44,440 --> 00:31:47,260
.ru site and a .jp site.

836
00:31:47,260 --> 00:31:49,030
But try and see if you can
create a network effect and

837
00:31:49,030 --> 00:31:53,060
connect your user base around
the world in one product.

838
00:31:53,060 --> 00:31:55,500
So that's where we'd like to
wrap up, is that our mission

839
00:31:55,500 --> 00:31:57,860
is to help organize the world's
information and make

840
00:31:57,860 --> 00:31:59,930
it universally accessible
and useful.

841
00:31:59,930 --> 00:32:02,160
We found this to be an
incredibly powerful tool

842
00:32:02,160 --> 00:32:03,620
across a range of
Google products

843
00:32:03,620 --> 00:32:05,050
and business processes.

844
00:32:05,050 --> 00:32:07,710
We've taken the best of that and
the core of that product

845
00:32:07,710 --> 00:32:09,400
knowledge and made it
available to you.

846
00:32:09,400 --> 00:32:11,250
And I'd like to hear now if
you have questions and

847
00:32:11,250 --> 00:32:14,000
resources about how we can help
other folks do the same.

848
00:32:14,000 --> 00:32:15,916
So thank you very much.

849
00:32:15,916 --> 00:32:18,670
[APPLAUSE]

850
00:32:18,670 --> 00:32:21,570
ROHIT KHARE: Some of
our related links.

851
00:32:21,570 --> 00:32:23,190
JOSH ESTELLE: So if there's
questions, there's two

852
00:32:23,190 --> 00:32:24,740
microphones if people
want to stand up.

853
00:32:24,740 --> 00:32:27,246
We've got about five minutes
for questions.

854
00:32:27,246 --> 00:32:28,200
ROHIT KHARE: Please.

855
00:32:28,200 --> 00:32:30,670
AUDIENCE: Hi I'm Luc, and I just
wanted to ask about the

856
00:32:30,670 --> 00:32:32,450
offline translation.

857
00:32:32,450 --> 00:32:35,340
Would you make this available
for business

858
00:32:35,340 --> 00:32:36,710
developers and so on?

859
00:32:36,710 --> 00:32:40,030
JOSH ESTELLE: So we don't
have plans to now.

860
00:32:40,030 --> 00:32:41,820
But this is good feedback,
right?

861
00:32:41,820 --> 00:32:44,440
We're always looking for ways
of what the next thing we

862
00:32:44,440 --> 00:32:47,460
might add to the API or how
we can expand that.

863
00:32:47,460 --> 00:32:50,130
We're really excited about
offline now, and we can

864
00:32:50,130 --> 00:32:51,570
understand that developers
would be too.

865
00:32:51,570 --> 00:32:53,880
So it's something we
can look into.

866
00:32:53,880 --> 00:32:55,310
ROHIT KHARE: Yeah, I'd love to
hear more about your use case.

867
00:32:55,310 --> 00:32:56,560
Thank you.

868
00:32:56,560 --> 00:32:58,430

869
00:32:58,430 --> 00:32:59,140
AUDIENCE: Hey.

870
00:32:59,140 --> 00:33:01,650
Do you provide a confidence
score in the API?

871
00:33:01,650 --> 00:33:04,300
So I could know when the
confidence is little, I would

872
00:33:04,300 --> 00:33:07,030
call in a human translator, and
if it's high, I'm good to

873
00:33:07,030 --> 00:33:07,720
go and can ship it out?

874
00:33:07,720 --> 00:33:08,070
JOSH ESTELLE: Yeah.

875
00:33:08,070 --> 00:33:10,490
So right now we don't.

876
00:33:10,490 --> 00:33:12,720
Providing confidence for
machine translation is

877
00:33:12,720 --> 00:33:16,130
actually a really, really
hard problem.

878
00:33:16,130 --> 00:33:17,860
You can imagine if you would
solve the problem of

879
00:33:17,860 --> 00:33:19,910
confidence, you would just
generate a bunch of

880
00:33:19,910 --> 00:33:22,270
translations and just pick the
one that had the highest

881
00:33:22,270 --> 00:33:23,810
confidence.

882
00:33:23,810 --> 00:33:26,580
So in some ways, generating
confidence is as hard as doing

883
00:33:26,580 --> 00:33:27,770
translation is.

884
00:33:27,770 --> 00:33:31,460
So internally, we've tried some
things around confidence,

885
00:33:31,460 --> 00:33:32,370
that sort of thing.

886
00:33:32,370 --> 00:33:36,820
None that we're happy with
enough that we've even exposed

887
00:33:36,820 --> 00:33:40,190
in our UI in anyway, or think
you would actually benefit

888
00:33:40,190 --> 00:33:41,770
from in the API.

889
00:33:41,770 --> 00:33:43,220
It's an understandable
thing to want.

890
00:33:43,220 --> 00:33:46,020
We want it too, but it's
really hard to do.

891
00:33:46,020 --> 00:33:48,160
So right now, we don't have
a way to do that.

892
00:33:48,160 --> 00:33:49,105
AUDIENCE: Thanks.

893
00:33:49,105 --> 00:33:50,500
JOSH ESTELLE: Yeah.

894
00:33:50,500 --> 00:33:51,190
OK.

895
00:33:51,190 --> 00:33:54,110
Any other questions?

896
00:33:54,110 --> 00:33:55,243
ROHIT KHARE: Well, we'll be
around for a few minutes.

897
00:33:55,243 --> 00:33:57,155
We'll be glad to talk about
individual scenarios.

898
00:33:57,155 --> 00:33:57,470
Thanks very much.

899
00:33:57,470 --> 00:33:58,690
JOSH ESTELLE: And we
have stickers if

900
00:33:58,690 --> 00:33:59,730
anyone wants stickers.

901
00:33:59,730 --> 00:34:01,530
ROHIT KHARE: Yes, we have lots
of Translate stickers.

902
00:34:01,530 --> 00:34:03,030
Thank you very much.

903
00:34:03,030 --> 00:34:04,280
JOSH ESTELLE: Thanks.

904
00:34:04,280 --> 00:34:06,025

